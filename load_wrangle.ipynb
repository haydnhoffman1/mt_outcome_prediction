{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1773bcac",
   "metadata": {},
   "source": [
    "# mRS prediction\n",
    "\n",
    "## 1. Load data\n",
    "\n",
    "- Remove duplicates\n",
    "- Remove cases with missing labels\n",
    "- Remove non-LVOs\n",
    "\n",
    "## 2. Wrangling\n",
    "\n",
    "- Remove MRNs\n",
    "- Create time variables\n",
    "- Create alternate outcomes: favorable functional status (mRS <= 2) and mortality\n",
    "- Create train/test sets and save as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9923fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5176e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e1ae49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 410 patients before removing duplicates\n",
      "There are 408 patients after removing duplicates\n",
      "There are 410 patients before removing duplicates\n",
      "There are 408 patients after removing duplicates\n",
      "There are 410 patients before removing duplicates\n",
      "There are 408 patients after removing duplicates\n",
      "There are 410 patients before removing duplicates\n",
      "There are 408 patients after removing duplicates\n",
      "There are 410 patients before removing duplicates\n",
      "There are 408 patients after removing duplicates\n",
      "There are 410 patients before removing duplicates\n",
      "There are 408 patients after removing duplicates\n"
     ]
    }
   ],
   "source": [
    "# load each csv file as a pd dataframe, drop duplicate mrn's, and add them to a list\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in os.listdir('data_export_3523'):\n",
    "    df = pd.read_csv(os.path.join('data_export_3523', file))\n",
    "    print('There are {} patients before removing duplicates'.format(df.shape[0]))\n",
    "    df = df.drop_duplicates(subset = 'mrn', keep = 'first')\n",
    "    print('There are {} patients after removing duplicates'.format(df.shape[0]))\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a86cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge each individual pd dataframe from the list\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    if i == 0:\n",
    "        dat = dfs[i]\n",
    "    else:\n",
    "        dat = dat.merge(dfs[i], how = 'left', on = 'mrn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37cb69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty column\n",
    "\n",
    "dat = dat.drop(['Unnamed: 21', 'Unnamed: 9'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b5c7d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 373 cases after removing patients with missing labels\n"
     ]
    }
   ],
   "source": [
    "# remove cases with missing labels\n",
    "\n",
    "dat = dat[dat['mrs_90'].notna()]\n",
    "print('there are {} cases after removing patients with missing labels'.format(dat.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb93525b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm there are no cases with missing labels\n",
    "\n",
    "any(dat['mrs_90'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7f27f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 357 cases after removing non-LVOs\n"
     ]
    }
   ],
   "source": [
    "# remove non-LVO cases\n",
    "\n",
    "sites_of_occlusion = ['M1', 'M2', 'ICA']\n",
    "\n",
    "dat = dat[dat['occ_site'].isin(sites_of_occlusion)]\n",
    "print('there are {} cases after removing non-LVOs'.format(dat.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "377e5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove MRNs\n",
    "\n",
    "dat = dat.drop('mrn', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e670b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time variables to datetime objects\n",
    "\n",
    "time_columns = ['lkw', 'arr', 'skin_puncture', 'first_pass_time', 'reperf']\n",
    "dat[time_columns] = dat[time_columns].apply(lambda x: pd.to_datetime(x, errors = 'coerce', utc = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbfdd606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate time intervals and convert to hours\n",
    "\n",
    "dat['time_to_arr'] = (dat['arr'] - dat['lkw']).dt.total_seconds() / 3600\n",
    "dat['time_to_puncture'] = (dat['skin_puncture'] - dat['arr']).dt.total_seconds() / 3600\n",
    "dat['time_to_first_pass'] = (dat['first_pass_time'] - dat['skin_puncture']).dt.total_seconds() / 3600\n",
    "dat['time_to_reperf'] = (dat['reperf'] - dat['lkw']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8c26da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove raw time variables\n",
    "\n",
    "dat = dat.drop(['arr', 'lkw', 'skin_puncture', 'first_pass_time', 'reperf'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f8f0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no heparin was used fill as 0\n",
    "\n",
    "dat['heparin'] = dat['heparin'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ac7eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate variables for each stent retriever used\n",
    "\n",
    "stent_retriever_types = ['Trevo', 'Solitaire', 'Embotrap', 'Capture']\n",
    "\n",
    "for stent in stent_retriever_types:\n",
    "    dat[stent.lower()] = np.where(dat['stent_ret_type'].str.contains(stent, na = False), 'Y', 'N')\n",
    "    \n",
    "dat = dat.drop('stent_ret_type', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0b788d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some categorical variables do not parse correctly; manually convert\n",
    "\n",
    "categorical_vars = ['stroke_etiol', 'mrs_90', 'ich_type', 'pre_mrs', 'coll_score', 'hyperdense']\n",
    "for var in categorical_vars:\n",
    "    dat[var] = dat[var].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0a46a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mortality outcome\n",
    "\n",
    "dat['mortality'] = np.where(dat['mrs_90'] == 6, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49b9611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create favorable functional status outcome\n",
    "\n",
    "dat['fav_mrs'] = np.where(dat['mrs_90'] <= 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4c7552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create death/severe disability outcome\n",
    "\n",
    "dat['dsd'] = np.where(dat['mrs_90'] >= 4, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "943a4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate df with outcomes for analysis\n",
    "\n",
    "outcomes = ['ich_type', 'ich_symptomatic', 'malig_infarct', 'mrs_90', 'fav_mrs', 'mortality', 'dsd']\n",
    "\n",
    "dat_outcomes = dat[outcomes]\n",
    "dat_outcomes.to_pickle('analysis/dat_outcomes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2645e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data for later use\n",
    "\n",
    "dat.to_pickle('dat_3523.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02997fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for splitting and saving data\n",
    "\n",
    "def split_save_data(outcomes, test_size = 0.2):\n",
    "    \n",
    "    for col_name, outcome in outcomes:\n",
    "    \n",
    "        X = dat.drop(['ich_type', 'ich_symptomatic', 'malig_infarct', 'mrs_90', 'fav_mrs', 'mortality', 'dsd'], axis = 1)\n",
    "        y = dat[col_name]\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = 42)\n",
    "        \n",
    "        print('split data for outcome: {}'.format(outcome))\n",
    "        print('there are {} training samples and {} testing samples\\n\\n'.format(X_train.shape[0], X_test.shape[0]))\n",
    "        \n",
    "        X_train.to_pickle(os.path.join('splits', outcome, 'X_train_' + outcome + '.pkl'))\n",
    "        X_test.to_pickle(os.path.join('splits', outcome, 'X_test_' + outcome + '.pkl'))\n",
    "        y_train.to_pickle(os.path.join('splits', outcome, 'y_train_' + outcome + '.pkl'))\n",
    "        y_test.to_pickle(os.path.join('splits', outcome, 'y_test_' + outcome + '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc20bacc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split data for outcome: functional_status\n",
      "there are 285 training samples and 72 testing samples\n",
      "\n",
      "\n",
      "split data for outcome: fav_functional_status\n",
      "there are 285 training samples and 72 testing samples\n",
      "\n",
      "\n",
      "split data for outcome: mortality\n",
      "there are 285 training samples and 72 testing samples\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# specify outcomes and split data\n",
    "\n",
    "outcomes = [('mrs_90', 'functional_status'),\n",
    "            ('fav_mrs', 'fav_functional_status'),\n",
    "            ('mortality', 'mortality'), \n",
    "            ('dsd', 'dsd')] \n",
    "\n",
    "split_save_data(outcomes = outcomes, test_size = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
