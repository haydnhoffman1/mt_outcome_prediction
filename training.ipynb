{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98c86e7",
   "metadata": {},
   "source": [
    "# Functional status (mRS) prediction\n",
    "\n",
    "## 5. Training\n",
    "\n",
    "### Favorable functional status (mRS >= 2)\n",
    "1. with MT data\n",
    "2. without MT data\n",
    "### Mortality (mRS 6)\n",
    "3. with MT data\n",
    "4. without MT data\n",
    "### Death/severe disability (mRS 4-6)\n",
    "5. with MT data\n",
    "6. without MT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b62981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.feature_selection import RFECV, SelectPercentile, chi2, VarianceThreshold\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imb_pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fd2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b244e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for training/saving results with a baseline LR model\n",
    "\n",
    "def baseline_lr(X_train, y_train, n_splits, n_repeats, scoring, fname):\n",
    "    \n",
    "    # make sure fname is valid\n",
    "    if os.path.isdir(os.path.split(fname)[0]) == False:\n",
    "        raise ValueError('Invalid directory specified')\n",
    "    \n",
    "    # identify categorical and continuous vars\n",
    "    cont_columns_selector = selector(dtype_exclude = object)\n",
    "    cat_columns_selector = selector(dtype_include = object)\n",
    "    cont_columns = cont_columns_selector(X_train)\n",
    "    cat_columns = cat_columns_selector(X_train)\n",
    "    all_columns = list(X_train.columns)\n",
    "\n",
    "    # instantiate the pre-processing pipelines for categorical and continuous variables\n",
    "    cat_preprocessor = Pipeline(steps = [\n",
    "            ('ordinal encoder', OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = np.nan)),\n",
    "            ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "            ('one hot encoder', OneHotEncoder(handle_unknown = 'ignore'))])\n",
    "    cont_preprocessor = Pipeline(steps = [\n",
    "            ('imputer', IterativeImputer(max_iter = 10000, random_state = 42)),\n",
    "            ('scaler', StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(\n",
    "            transformers = [\n",
    "            ('cont', cont_preprocessor, cont_columns), \n",
    "            ('cat', cat_preprocessor, cat_columns)])\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        steps = [('preprocessor', preprocessor), \n",
    "                 ('logistic regression', LogisticRegression(penalty = 'none', random_state = 42, \n",
    "                                                            max_iter = 10000))])\n",
    "\n",
    "    cv = RepeatedStratifiedKFold(n_splits = n_splits, n_repeats = n_repeats, random_state = 42)\n",
    "    print('Evaluating baseline logistic regression model with CV using {} splits and {} repeats'.\n",
    "          format(n_splits, n_repeats))\n",
    "    scores = list(cross_val_score(pipe, X_train, y_train, scoring = scoring, cv = cv))\n",
    "\n",
    "    pd.DataFrame(scores).to_pickle(fname)\n",
    "    print('Mean AUC for baseline logistic regression model: {} +/- {}'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    return pipe, pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53240625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for screening models with default settings and minimal preprocessing\n",
    "\n",
    "def screen_models(models, score, X_train, y_train, fname, fname_df):\n",
    "    results = []\n",
    "    result_file = open(fname, 'a')\n",
    "    \n",
    "    # identify categorical and continuous vars\n",
    "    cont_columns_selector = selector(dtype_exclude = object)\n",
    "    cat_columns_selector = selector(dtype_include = object)\n",
    "    cont_columns = cont_columns_selector(X_train)\n",
    "    cat_columns = cat_columns_selector(X_train)\n",
    "    all_columns = list(X_train.columns)\n",
    "    \n",
    "    # instantiate the pre-processing pipelines for categorical and continuous variables\n",
    "    cat_preprocessor = Pipeline(steps = [\n",
    "        ('ordinal encoder', OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = np.nan)),\n",
    "        ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "        ('one hot encoder', OneHotEncoder(handle_unknown = 'ignore'))])\n",
    "    cont_preprocessor = Pipeline(steps = [\n",
    "        ('imputer', IterativeImputer(max_iter = 10000, random_state = 0)),\n",
    "        ('scaler', StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "        ('cont', cont_preprocessor, cont_columns), \n",
    "        ('cat', cat_preprocessor, cat_columns)])  \n",
    "    \n",
    "    for model_name, Model, params_list in models:\n",
    "        print('Evaluating {}...'.format(model_name))\n",
    "        for params in params_list:\n",
    "            model = Pipeline(steps = [\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('model', Model(**params))\n",
    "            ])\n",
    "            cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 10)\n",
    "            scores = list(cross_val_score(model, X_train, y_train, scoring = score, cv = cv))\n",
    "            results.append((model_name, model, params, np.median(scores), np.percentile(scores, [25, 75]), scores))\n",
    "    \n",
    "    results.sort(key = lambda x:x[-3], reverse = True)\n",
    "    \n",
    "    # write score summary to txt file\n",
    "    result_file.write('\\nmedian {} scores:\\n\\n'.format(score))\n",
    "    for modelname, model, params, median, iqr, scores in results:\n",
    "        result_file.write(str(modelname) + '\\t' + str(params) + '\\t' + str(median) + '\\t' + '+/- ' + str(iqr) + '\\n')\n",
    "    result_file.close()\n",
    "    \n",
    "    # write scores to dataframe\n",
    "    df = pd.DataFrame()\n",
    "    for modelname, model, params, median, iqr, scores in results:\n",
    "        column_name = str(modelname) + str(params)\n",
    "        df[column_name] = scores\n",
    "    df.to_pickle(fname_df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a252f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for nested CV to find best parameters for sklearn models\n",
    "\n",
    "def eval_params(fname_text, fname_results, tuning_model, param_grid, X_train, y_train):\n",
    "    \n",
    "    results = []\n",
    "    result_file = open(fname_text, 'a')\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "    fold_no = 1\n",
    "    \n",
    "    # identify categorical and continuous vars\n",
    "    cont_columns_selector = selector(dtype_exclude = object)\n",
    "    cat_columns_selector = selector(dtype_include = object)\n",
    "    cont_columns = cont_columns_selector(X_train)\n",
    "    cat_columns = cat_columns_selector(X_train)\n",
    "    all_columns = list(X_train.columns)\n",
    "    \n",
    "    # instantiate the pre-processing pipelines for categorical and continuous variables\n",
    "    cat_preprocessor = Pipeline(steps = [\n",
    "        ('ordinal encoder', OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = np.nan)),\n",
    "        ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "        ('one hot encoder', OneHotEncoder(handle_unknown = 'ignore')),\n",
    "        ('selector', SelectPercentile(chi2))])\n",
    "    cont_preprocessor = Pipeline(steps = [\n",
    "        ('imputer', IterativeImputer(max_iter = 10000, random_state = 0)),\n",
    "        ('variance_threshold', VarianceThreshold()),\n",
    "        ('scaler', StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "        ('cont', cont_preprocessor, cont_columns), \n",
    "        ('cat', cat_preprocessor, cat_columns)])  \n",
    "    \n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "\n",
    "        X_train_split, X_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_split, y_test = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        # find best model params\n",
    "        print('finding best model parameters for fold number {}'.format(fold_no))\n",
    "        model = imb_pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('SMOTE', SMOTE()),\n",
    "            ('classifier', tuning_model)\n",
    "        ])\n",
    "        grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1, cv = 5, error_score = 'raise', \n",
    "                           scoring = 'roc_auc', verbose = 3)\n",
    "        grid.fit(X_train_split, y_train_split)\n",
    "        \n",
    "        # evaluate best model params on outer fold\n",
    "        print('evaluating model for fold number {}'.format(fold_no))\n",
    "        best_params = grid.best_params_\n",
    "        print(best_params)\n",
    "        best_model = grid.best_estimator_\n",
    "        score = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "        results.append((best_params, score))\n",
    "        print('parameters: {}'.format(str(best_params)))\n",
    "        print('AUC score: {}'.format(score))\n",
    "        fold_no += 1\n",
    "\n",
    "    results.sort(key = lambda x:x[-1], reverse = True)\n",
    "    result_file.write('\\nAUC scores:\\n\\n')\n",
    "    \n",
    "    # write score summary to text file\n",
    "    for best_params, score in results:\n",
    "        result_file.write(str(best_params) + '\\t' + str(score) + '\\n')\n",
    "    result_file.close()\n",
    "    \n",
    "    # write scores to dataframe:\n",
    "    df = pd.DataFrame(results, columns = ['params', 'score'])\n",
    "    df.to_pickle(fname_results)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2498d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for retraining tuned model + saving\n",
    "\n",
    "def retrain_save(X, y, percentile, threshold, final_model, fname):\n",
    "    \n",
    "    # identify categorical and continuous vars\n",
    "    cont_columns_selector = selector(dtype_exclude = object)\n",
    "    cat_columns_selector = selector(dtype_include = object)\n",
    "    cont_columns = cont_columns_selector(X)\n",
    "    cat_columns = cat_columns_selector(X)\n",
    "    all_columns = list(X.columns)\n",
    "    \n",
    "    # instantiate the pre-processing pipelines for categorical and continuous variables\n",
    "    cat_preprocessor = Pipeline(steps = [\n",
    "        ('ordinal encoder', OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = np.nan)),\n",
    "        ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "        ('one hot encoder', OneHotEncoder(handle_unknown = 'ignore')),\n",
    "        ('selector', SelectPercentile(chi2, percentile = percentile))])\n",
    "    cont_preprocessor = Pipeline(steps = [\n",
    "        ('imputer', IterativeImputer(max_iter = 10000, random_state = 0)),\n",
    "        ('variance_threshold', VarianceThreshold(threshold = threshold)),\n",
    "        ('scaler', StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "        ('cont', cont_preprocessor, cont_columns), \n",
    "        ('cat', cat_preprocessor, cat_columns)])  \n",
    "    \n",
    "    model = imb_pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('SMOTE', SMOTE()),\n",
    "            ('classifier', final_model)\n",
    "        ])\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    print('Training complete for {}'.format(final_model))\n",
    "    \n",
    "    pickle.dump(model, open(fname, 'wb'))\n",
    "    if os.path.exists(fname):\n",
    "        print('Model saved')\n",
    "    else:\n",
    "        print('Error saving model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cd59ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for training LR model + saving\n",
    "\n",
    "def train_save_lr(X, y, fname):\n",
    "    \n",
    "    # identify categorical and continuous vars\n",
    "    cont_columns_selector = selector(dtype_exclude = object)\n",
    "    cat_columns_selector = selector(dtype_include = object)\n",
    "    cont_columns = cont_columns_selector(X)\n",
    "    cat_columns = cat_columns_selector(X)\n",
    "    all_columns = list(X.columns)\n",
    "\n",
    "    # instantiate the pre-processing pipelines for categorical and continuous variables\n",
    "    cat_preprocessor = Pipeline(steps = [\n",
    "            ('ordinal encoder', OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = np.nan)),\n",
    "            ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "            ('one hot encoder', OneHotEncoder(handle_unknown = 'ignore'))])\n",
    "    cont_preprocessor = Pipeline(steps = [\n",
    "            ('imputer', IterativeImputer(max_iter = 10000, random_state = 42)),\n",
    "            ('scaler', StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(\n",
    "            transformers = [\n",
    "            ('cont', cont_preprocessor, cont_columns), \n",
    "            ('cat', cat_preprocessor, cat_columns)])\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        steps = [('preprocessor', preprocessor), \n",
    "                 ('logistic regression', LogisticRegression(penalty = 'none', random_state = 42, \n",
    "                                                            max_iter = 10000))])\n",
    "    \n",
    "    pipe.fit(X, y)\n",
    "    print('Training complete')\n",
    "    \n",
    "    pickle.dump(pipe, open(fname, 'wb'))\n",
    "    if os.path.exists(fname):\n",
    "        print('Model saved')\n",
    "    else:\n",
    "        print('Error saving model')\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd37339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_grid = [\n",
    "    {\n",
    "        'preprocessor__cat__selector__percentile': np.linspace(10, 100, num = 10), \n",
    "        'preprocessor__cont__variance_threshold__threshold': np.linspace(0.4, 0.6, num = 3), \n",
    "        'classifier__C': [0.01, 0.1, 1.0, 10], \n",
    "        'classifier__gamma': ['scale', 'auto']\n",
    "    }    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14104e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = [\n",
    "    {\n",
    "        'preprocessor__cat__selector__percentile': np.linspace(10, 100, num = 10), \n",
    "        'preprocessor__cont__variance_threshold__threshold': np.linspace(0.4, 0.6, num = 3), \n",
    "        'classifier__n_estimators': [int(x) for x in np.linspace(500, 2000, num = 4)],\n",
    "        'classifier__max_depth': np.linspace(20, 100, num = 5),\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4]\n",
    "    }    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60289de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_grid = [\n",
    "    {\n",
    "        'preprocessor__cat__selector__percentile': np.linspace(10, 100, num = 10), \n",
    "        'preprocessor__cont__variance_threshold__threshold': np.linspace(0.4, 0.6, num = 3), \n",
    "        'classifier__hidden_layer_sizes': [(10,), (10, 10,), (10, 10, 10,), (20,), (20, 20,), (20, 20, 20,), \n",
    "                                           (30,), (30, 30,), (30, 30, 30,)],\n",
    "        'classifier__beta_1': np.linspace(0.3, 0.9, num = 3),\n",
    "        'classifier__beta_2': np.linspace(0.3, 0.9, num = 3)\n",
    "    }    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5938dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_grid = [\n",
    "    {\n",
    "        'preprocessor__cat__selector__percentile': np.linspace(10, 100, num = 10), \n",
    "        'preprocessor__cont__variance_threshold__threshold': np.linspace(0.4, 0.6, num = 3), \n",
    "        'classifier__var_smoothing': np.logspace(0, -9, num = 10)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f7b1f",
   "metadata": {},
   "source": [
    "### 1. Favorable functional status prediction - with MT data\n",
    "\n",
    "Model training includes variables from the mechanical thrombectomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "31e1400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mt = pd.read_pickle('transformed_datasets/fav_functional_status/mt_data/X_train_trans_mt.pkl')\n",
    "y_train = np.load('transformed_datasets/fav_functional_status/y_train_trans.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "126f5b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline logistic regression model with CV using 5 splits and 10 repeats\n",
      "Mean AUC for baseline logistic regression model: 0.7718741032998565 +/- 0.0568870610395341\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline LR model\n",
    "\n",
    "pipe_lr_mt, scores_lr_mt = baseline_lr(X_train = X_train_mt, y_train = y_train, n_splits = 5, n_repeats = 10, \n",
    "                                       scoring = 'roc_auc', \n",
    "                                       fname = 'experiments/fav_functional_status/mt_data/baseline_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cce988f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to screen\n",
    "\n",
    "max_iter = 10000\n",
    "\n",
    "en_params = [{'max_iter': max_iter}]\n",
    "dec_tree_params = [{'criterion': 'gini'}, {'criterion': 'entropy'}]\n",
    "rand_for_params = [{'criterion': 'gini', 'n_estimators': 500}, {'criterion': 'entropy', 'n_estimators': 500}]\n",
    "kneighbors_params = [{'n_neighbors': 3}, {'n_neighbors': 5}]\n",
    "naive_bayes_params = [{}]\n",
    "svc_params = [{'C': 0.01}, {'C': 0.1}, {'C': 1}, {'C': 10}]\n",
    "xgb_params = [{'use_label_encoder': False}]\n",
    "lgbm_params = [{}]\n",
    "mlp_params = [{'hidden_layer_sizes': (10,), 'max_iter': max_iter}, {'hidden_layer_sizes': (10, 10,), 'max_iter': max_iter}, \n",
    "              {'hidden_layer_sizes': (10, 10, 10,), 'max_iter': max_iter}]\n",
    "\n",
    "models = [\n",
    "    ['elastic net', ElasticNet, en_params],\n",
    "    ['decision tree', DecisionTreeClassifier, dec_tree_params],\n",
    "    ['random forest', RandomForestClassifier, rand_for_params],\n",
    "    ['k neighbors', KNeighborsClassifier, kneighbors_params],\n",
    "    ['naive bayes', GaussianNB, naive_bayes_params],\n",
    "    ['support vector machines', SVC, svc_params],\n",
    "    ['XG boost', xgb.XGBClassifier, xgb_params],\n",
    "    ['Light GBM', LGBMClassifier, lgbm_params],\n",
    "    ['MLP', MLPClassifier, mlp_params]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1574b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating elastic net...\n",
      "Evaluating decision tree...\n",
      "Evaluating random forest...\n",
      "Evaluating k neighbors...\n",
      "Evaluating naive bayes...\n",
      "Evaluating support vector machines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/impute/_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XG boost...\n",
      "Evaluating Light GBM...\n",
      "Evaluating MLP...\n"
     ]
    }
   ],
   "source": [
    "# screen models\n",
    "\n",
    "fname = 'experiments/fav_functional_status/mt_data/init_screening_summary' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_df = 'experiments/fav_functional_status/mt_data/init_screening_results' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl' \n",
    "\n",
    "init_screen_mt = screen_models(models = models, score = 'roc_auc', X_train = X_train_mt, y_train = y_train, \n",
    "                              fname = fname, fname_df = fname_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fcb90a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support vector machines{'C': 1}</th>\n",
       "      <th>support vector machines{'C': 0.01}</th>\n",
       "      <th>support vector machines{'C': 0.1}</th>\n",
       "      <th>support vector machines{'C': 10}</th>\n",
       "      <th>random forest{'criterion': 'gini', 'n_estimators': 500}</th>\n",
       "      <th>random forest{'criterion': 'entropy', 'n_estimators': 500}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}</th>\n",
       "      <th>XG boost{'use_label_encoder': False}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}</th>\n",
       "      <th>Light GBM{}</th>\n",
       "      <th>naive bayes{}</th>\n",
       "      <th>k neighbors{'n_neighbors': 5}</th>\n",
       "      <th>k neighbors{'n_neighbors': 3}</th>\n",
       "      <th>decision tree{'criterion': 'entropy'}</th>\n",
       "      <th>decision tree{'criterion': 'gini'}</th>\n",
       "      <th>elastic net{'max_iter': 10000}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797484</td>\n",
       "      <td>0.796841</td>\n",
       "      <td>0.792268</td>\n",
       "      <td>0.775598</td>\n",
       "      <td>0.764498</td>\n",
       "      <td>0.758314</td>\n",
       "      <td>0.754566</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.749872</td>\n",
       "      <td>0.743790</td>\n",
       "      <td>0.740431</td>\n",
       "      <td>0.715809</td>\n",
       "      <td>0.693907</td>\n",
       "      <td>0.683881</td>\n",
       "      <td>0.631020</td>\n",
       "      <td>0.638249</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.066230</td>\n",
       "      <td>0.054273</td>\n",
       "      <td>0.066496</td>\n",
       "      <td>0.061575</td>\n",
       "      <td>0.063794</td>\n",
       "      <td>0.064760</td>\n",
       "      <td>0.061257</td>\n",
       "      <td>0.067691</td>\n",
       "      <td>0.061448</td>\n",
       "      <td>0.065571</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>0.062453</td>\n",
       "      <td>0.077251</td>\n",
       "      <td>0.055006</td>\n",
       "      <td>0.068572</td>\n",
       "      <td>0.072898</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.642647</td>\n",
       "      <td>0.669118</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.619118</td>\n",
       "      <td>0.602896</td>\n",
       "      <td>0.641176</td>\n",
       "      <td>0.620588</td>\n",
       "      <td>0.555882</td>\n",
       "      <td>0.630882</td>\n",
       "      <td>0.586890</td>\n",
       "      <td>0.616176</td>\n",
       "      <td>0.533088</td>\n",
       "      <td>0.463235</td>\n",
       "      <td>0.554878</td>\n",
       "      <td>0.472059</td>\n",
       "      <td>0.480147</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.765244</td>\n",
       "      <td>0.750762</td>\n",
       "      <td>0.750368</td>\n",
       "      <td>0.737132</td>\n",
       "      <td>0.725825</td>\n",
       "      <td>0.703676</td>\n",
       "      <td>0.716176</td>\n",
       "      <td>0.700139</td>\n",
       "      <td>0.709205</td>\n",
       "      <td>0.710294</td>\n",
       "      <td>0.692279</td>\n",
       "      <td>0.684926</td>\n",
       "      <td>0.641544</td>\n",
       "      <td>0.643674</td>\n",
       "      <td>0.586213</td>\n",
       "      <td>0.598498</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.805882</td>\n",
       "      <td>0.804591</td>\n",
       "      <td>0.801704</td>\n",
       "      <td>0.784559</td>\n",
       "      <td>0.770588</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.760482</td>\n",
       "      <td>0.748529</td>\n",
       "      <td>0.747794</td>\n",
       "      <td>0.747767</td>\n",
       "      <td>0.732353</td>\n",
       "      <td>0.718158</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.685662</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.630882</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.844118</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.806618</td>\n",
       "      <td>0.803067</td>\n",
       "      <td>0.805147</td>\n",
       "      <td>0.796691</td>\n",
       "      <td>0.788971</td>\n",
       "      <td>0.793015</td>\n",
       "      <td>0.797982</td>\n",
       "      <td>0.792647</td>\n",
       "      <td>0.757023</td>\n",
       "      <td>0.744669</td>\n",
       "      <td>0.724265</td>\n",
       "      <td>0.675184</td>\n",
       "      <td>0.677112</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.886765</td>\n",
       "      <td>0.913235</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.903676</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.860294</td>\n",
       "      <td>0.891176</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857353</td>\n",
       "      <td>0.916176</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.860294</td>\n",
       "      <td>0.808088</td>\n",
       "      <td>0.807353</td>\n",
       "      <td>0.794853</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       support vector machines{'C': 1}  support vector machines{'C': 0.01}  \\\n",
       "count                        50.000000                           50.000000   \n",
       "mean                          0.797484                            0.796841   \n",
       "std                           0.066230                            0.054273   \n",
       "min                           0.642647                            0.669118   \n",
       "25%                           0.765244                            0.750762   \n",
       "50%                           0.805882                            0.804591   \n",
       "75%                           0.844118                            0.845588   \n",
       "max                           0.911765                            0.886765   \n",
       "\n",
       "       support vector machines{'C': 0.1}  support vector machines{'C': 10}  \\\n",
       "count                          50.000000                         50.000000   \n",
       "mean                            0.792268                          0.775598   \n",
       "std                             0.066496                          0.061575   \n",
       "min                             0.617647                          0.619118   \n",
       "25%                             0.750368                          0.737132   \n",
       "50%                             0.801704                          0.784559   \n",
       "75%                             0.844086                          0.806618   \n",
       "max                             0.913235                          0.929412   \n",
       "\n",
       "       random forest{'criterion': 'gini', 'n_estimators': 500}  \\\n",
       "count                                          50.000000         \n",
       "mean                                            0.764498         \n",
       "std                                             0.063794         \n",
       "min                                             0.602896         \n",
       "25%                                             0.725825         \n",
       "50%                                             0.770588         \n",
       "75%                                             0.803067         \n",
       "max                                             0.903676         \n",
       "\n",
       "       random forest{'criterion': 'entropy', 'n_estimators': 500}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.758314            \n",
       "std                                             0.064760            \n",
       "min                                             0.641176            \n",
       "25%                                             0.703676            \n",
       "50%                                             0.762500            \n",
       "75%                                             0.805147            \n",
       "max                                             0.876471            \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}  \\\n",
       "count                                          50.000000     \n",
       "mean                                            0.754566     \n",
       "std                                             0.061257     \n",
       "min                                             0.620588     \n",
       "25%                                             0.716176     \n",
       "50%                                             0.760482     \n",
       "75%                                             0.796691     \n",
       "max                                             0.860294     \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.746269            \n",
       "std                                             0.067691            \n",
       "min                                             0.555882            \n",
       "25%                                             0.700139            \n",
       "50%                                             0.748529            \n",
       "75%                                             0.788971            \n",
       "max                                             0.891176            \n",
       "\n",
       "       XG boost{'use_label_encoder': False}  \\\n",
       "count                             50.000000   \n",
       "mean                               0.749872   \n",
       "std                                0.061448   \n",
       "min                                0.630882   \n",
       "25%                                0.709205   \n",
       "50%                                0.747794   \n",
       "75%                                0.793015   \n",
       "max                                0.875000   \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}  Light GBM{}  \\\n",
       "count                                          50.000000         50.000000   \n",
       "mean                                            0.743790          0.740431   \n",
       "std                                             0.065571          0.068307   \n",
       "min                                             0.586890          0.616176   \n",
       "25%                                             0.710294          0.692279   \n",
       "50%                                             0.747767          0.732353   \n",
       "75%                                             0.797982          0.792647   \n",
       "max                                             0.857353          0.916176   \n",
       "\n",
       "       naive bayes{}  k neighbors{'n_neighbors': 5}  \\\n",
       "count      50.000000                      50.000000   \n",
       "mean        0.715809                       0.693907   \n",
       "std         0.062453                       0.077251   \n",
       "min         0.533088                       0.463235   \n",
       "25%         0.684926                       0.641544   \n",
       "50%         0.718158                       0.694118   \n",
       "75%         0.757023                       0.744669   \n",
       "max         0.825000                       0.860294   \n",
       "\n",
       "       k neighbors{'n_neighbors': 3}  decision tree{'criterion': 'entropy'}  \\\n",
       "count                      50.000000                              50.000000   \n",
       "mean                        0.683881                               0.631020   \n",
       "std                         0.055006                               0.068572   \n",
       "min                         0.554878                               0.472059   \n",
       "25%                         0.643674                               0.586213   \n",
       "50%                         0.685662                               0.637500   \n",
       "75%                         0.724265                               0.675184   \n",
       "max                         0.808088                               0.807353   \n",
       "\n",
       "       decision tree{'criterion': 'gini'}  elastic net{'max_iter': 10000}  \n",
       "count                           50.000000                            50.0  \n",
       "mean                             0.638249                             0.5  \n",
       "std                              0.072898                             0.0  \n",
       "min                              0.480147                             0.5  \n",
       "25%                              0.598498                             0.5  \n",
       "50%                              0.630882                             0.5  \n",
       "75%                              0.677112                             0.5  \n",
       "max                              0.794853                             0.5  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_screen_mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "923be392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.8455882352941175\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 60.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 60.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.8852941176470588\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7963235294117648\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.8220588235294117\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.7469512195121951\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.885294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.845588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.822059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.796324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.746951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__C': 0.1, 'classifier__gamma': 'a...  0.885294\n",
       "1  {'classifier__C': 1.0, 'classifier__gamma': 'a...  0.845588\n",
       "2  {'classifier__C': 1.0, 'classifier__gamma': 'a...  0.822059\n",
       "3  {'classifier__C': 1.0, 'classifier__gamma': 'a...  0.796324\n",
       "4  {'classifier__C': 1.0, 'classifier__gamma': 'a...  0.746951"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune SVM\n",
    "\n",
    "fname_text = 'experiments/fav_functional_status/mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/fav_functional_status/mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = SVC(probability = True), param_grid = svm_grid, X_train = X_train_mt, \n",
    "            y_train = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf6c6590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.8073529411764706\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__max_depth': 40.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 40.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7735294117647059\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.8338235294117647\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 2000, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 2000, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7647058823529411\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.8307926829268293\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__max_depth': 60.0, 'classifier__m...</td>\n",
       "      <td>0.833824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__max_depth': 60.0, 'classifier__m...</td>\n",
       "      <td>0.830793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__max_depth': 60.0, 'classifier__m...</td>\n",
       "      <td>0.807353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__max_depth': 40.0, 'classifier__m...</td>\n",
       "      <td>0.773529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__max_depth': 60.0, 'classifier__m...</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__max_depth': 60.0, 'classifier__m...  0.833824\n",
       "1  {'classifier__max_depth': 60.0, 'classifier__m...  0.830793\n",
       "2  {'classifier__max_depth': 60.0, 'classifier__m...  0.807353\n",
       "3  {'classifier__max_depth': 40.0, 'classifier__m...  0.773529\n",
       "4  {'classifier__max_depth': 60.0, 'classifier__m...  0.764706"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune RF\n",
    "\n",
    "fname_text = 'experiments/fav_functional_status/mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/fav_functional_status/mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = RandomForestClassifier(), param_grid = rf_grid, X_train = X_train_mt, \n",
    "            y_train = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4abb4280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__beta_1': 0.9, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (10,), 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__beta_1': 0.9, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (10,), 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.75\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__beta_1': 0.3, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__beta_1': 0.3, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7897058823529411\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__beta_1': 0.9, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (10, 10, 10), 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__beta_1': 0.9, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (10, 10, 10), 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.736764705882353\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__beta_1': 0.9, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.9, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.8264705882352941\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__beta_1': 0.3, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__beta_1': 0.3, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.7606707317073171\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__beta_1': 0.9, 'classifier__beta_...</td>\n",
       "      <td>0.826471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__beta_1': 0.3, 'classifier__beta_...</td>\n",
       "      <td>0.789706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__beta_1': 0.3, 'classifier__beta_...</td>\n",
       "      <td>0.760671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__beta_1': 0.9, 'classifier__beta_...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__beta_1': 0.9, 'classifier__beta_...</td>\n",
       "      <td>0.736765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__beta_1': 0.9, 'classifier__beta_...  0.826471\n",
       "1  {'classifier__beta_1': 0.3, 'classifier__beta_...  0.789706\n",
       "2  {'classifier__beta_1': 0.3, 'classifier__beta_...  0.760671\n",
       "3  {'classifier__beta_1': 0.9, 'classifier__beta_...  0.750000\n",
       "4  {'classifier__beta_1': 0.9, 'classifier__beta_...  0.736765"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune MLP\n",
    "\n",
    "fname_text = 'experiments/fav_functional_status/mt_data/mlp_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/fav_functional_status/mt_data/mlp_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = MLPClassifier(max_iter = 10000), param_grid = mlp_grid, X_train = X_train_mt, \n",
    "            y_train = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cfb9dd93",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for RandomForestClassifier(max_depth=60, min_samples_leaf=4, n_estimators=1000)\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=0)),\n",
       "                                                                  ('variance_threshold',\n",
       "                                                                   VarianceThreshold(threshold=0.5)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'heparin',\n",
       "                                                   'num_pas...\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'ptas',\n",
       "                                                   'stent_ret', 'aspiration',\n",
       "                                                   'first_pass_reperf',\n",
       "                                                   'procedure_ap', 'gen_anes',\n",
       "                                                   'hypoten_mt', 'tici_success',\n",
       "                                                   'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('SMOTE', SMOTE()),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_depth=60, min_samples_leaf=4,\n",
       "                                        n_estimators=1000))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain best model on entire training set and save model\n",
    "\n",
    "retrain_save(X = X_train_mt, \n",
    "             y = y_train, \n",
    "             percentile = 10, \n",
    "             threshold = 0.5, \n",
    "             final_model = RandomForestClassifier(max_depth = 60, \n",
    "                                                 min_samples_leaf = 4,\n",
    "                                                 min_samples_split = 2, \n",
    "                                                 n_estimators = 1000), \n",
    "             fname = 'models/fav_functional_status/mt_data/final_rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7150f287",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=42)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'heparin',\n",
       "                                                   'num_pass', 'fluoro_time',\n",
       "                                                   'time_to_arr',\n",
       "                                                   'time_to_puncture',\n",
       "                                                   'time...\n",
       "                                                   'stroke_etiol', 'sex',\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'ptas',\n",
       "                                                   'stent_ret', 'aspiration',\n",
       "                                                   'first_pass_reperf',\n",
       "                                                   'procedure_ap', 'gen_anes',\n",
       "                                                   'hypoten_mt', 'tici_success',\n",
       "                                                   'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('logistic regression',\n",
       "                 LogisticRegression(max_iter=10000, penalty='none',\n",
       "                                    random_state=42))])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train LR model on entire training set and save model\n",
    "\n",
    "train_save_lr(X = X_train_mt, \n",
    "             y = y_train, \n",
    "             fname = 'models/fav_functional_status/mt_data/final_lr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23075ba",
   "metadata": {},
   "source": [
    "### 2. Favorable functional status prediction - without MT data\n",
    "Model training does not include variables from the mechanical thrombectomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3377cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nomt = pd.read_pickle('transformed_datasets/fav_functional_status/no_mt_data/X_train_trans_nomt.pkl')\n",
    "y_train = np.load('transformed_datasets/fav_functional_status/y_train_trans.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4012b4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline logistic regression model with CV using 5 splits and 10 repeats\n",
      "Mean AUC for baseline logistic regression model: 0.7653073888091823 +/- 0.05668853285375565\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline LR model\n",
    "\n",
    "pipe_lr_nomt, scores_lr_nomt = baseline_lr(X_train = X_train_nomt, y_train = y_train, n_splits = 5, n_repeats = 10, \n",
    "                                       scoring = 'roc_auc', \n",
    "                                       fname = 'experiments/fav_functional_status/no_mt_data/baseline_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5940838b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating elastic net...\n",
      "Evaluating decision tree...\n",
      "Evaluating random forest...\n",
      "Evaluating k neighbors...\n",
      "Evaluating naive bayes...\n",
      "Evaluating support vector machines...\n",
      "Evaluating XG boost...\n",
      "Evaluating Light GBM...\n",
      "Evaluating MLP...\n"
     ]
    }
   ],
   "source": [
    "# screen models\n",
    "\n",
    "fname = 'experiments/fav_functional_status/no_mt_data/init_screening_summary' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_df = 'experiments/fav_functional_status/no_mt_data/init_screening_results' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl' \n",
    "\n",
    "init_screen_nomt = screen_models(models = models, score = 'roc_auc', X_train = X_train_nomt, y_train = y_train, \n",
    "                              fname = fname, fname_df = fname_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b81cd7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support vector machines{'C': 1}</th>\n",
       "      <th>random forest{'criterion': 'entropy', 'n_estimators': 500}</th>\n",
       "      <th>support vector machines{'C': 0.1}</th>\n",
       "      <th>support vector machines{'C': 0.01}</th>\n",
       "      <th>random forest{'criterion': 'gini', 'n_estimators': 500}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}</th>\n",
       "      <th>support vector machines{'C': 10}</th>\n",
       "      <th>naive bayes{}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}</th>\n",
       "      <th>XG boost{'use_label_encoder': False}</th>\n",
       "      <th>Light GBM{}</th>\n",
       "      <th>k neighbors{'n_neighbors': 5}</th>\n",
       "      <th>k neighbors{'n_neighbors': 3}</th>\n",
       "      <th>decision tree{'criterion': 'entropy'}</th>\n",
       "      <th>decision tree{'criterion': 'gini'}</th>\n",
       "      <th>elastic net{'max_iter': 10000}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.739769</td>\n",
       "      <td>0.731725</td>\n",
       "      <td>0.735853</td>\n",
       "      <td>0.735799</td>\n",
       "      <td>0.726879</td>\n",
       "      <td>0.689289</td>\n",
       "      <td>0.690042</td>\n",
       "      <td>0.693569</td>\n",
       "      <td>0.684504</td>\n",
       "      <td>0.679984</td>\n",
       "      <td>0.680801</td>\n",
       "      <td>0.684174</td>\n",
       "      <td>0.643374</td>\n",
       "      <td>0.615450</td>\n",
       "      <td>0.576135</td>\n",
       "      <td>0.582048</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.056570</td>\n",
       "      <td>0.057517</td>\n",
       "      <td>0.048290</td>\n",
       "      <td>0.055810</td>\n",
       "      <td>0.063630</td>\n",
       "      <td>0.060079</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>0.066492</td>\n",
       "      <td>0.076228</td>\n",
       "      <td>0.060335</td>\n",
       "      <td>0.068725</td>\n",
       "      <td>0.072771</td>\n",
       "      <td>0.072418</td>\n",
       "      <td>0.071068</td>\n",
       "      <td>0.063252</td>\n",
       "      <td>0.070848</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.613235</td>\n",
       "      <td>0.600735</td>\n",
       "      <td>0.626471</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.564024</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.538110</td>\n",
       "      <td>0.502206</td>\n",
       "      <td>0.536765</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.457353</td>\n",
       "      <td>0.478676</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.438235</td>\n",
       "      <td>0.442647</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.711029</td>\n",
       "      <td>0.701639</td>\n",
       "      <td>0.701610</td>\n",
       "      <td>0.697426</td>\n",
       "      <td>0.688215</td>\n",
       "      <td>0.648399</td>\n",
       "      <td>0.636029</td>\n",
       "      <td>0.653309</td>\n",
       "      <td>0.618936</td>\n",
       "      <td>0.633456</td>\n",
       "      <td>0.638971</td>\n",
       "      <td>0.644485</td>\n",
       "      <td>0.605882</td>\n",
       "      <td>0.579044</td>\n",
       "      <td>0.527094</td>\n",
       "      <td>0.539652</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.743275</td>\n",
       "      <td>0.739136</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.734559</td>\n",
       "      <td>0.732721</td>\n",
       "      <td>0.708824</td>\n",
       "      <td>0.703605</td>\n",
       "      <td>0.693382</td>\n",
       "      <td>0.690441</td>\n",
       "      <td>0.688971</td>\n",
       "      <td>0.688235</td>\n",
       "      <td>0.684451</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.608528</td>\n",
       "      <td>0.576838</td>\n",
       "      <td>0.566544</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.774632</td>\n",
       "      <td>0.769853</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.770588</td>\n",
       "      <td>0.765074</td>\n",
       "      <td>0.734559</td>\n",
       "      <td>0.743221</td>\n",
       "      <td>0.728842</td>\n",
       "      <td>0.740441</td>\n",
       "      <td>0.719118</td>\n",
       "      <td>0.723162</td>\n",
       "      <td>0.727941</td>\n",
       "      <td>0.690441</td>\n",
       "      <td>0.669669</td>\n",
       "      <td>0.610294</td>\n",
       "      <td>0.609191</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.820588</td>\n",
       "      <td>0.860294</td>\n",
       "      <td>0.874265</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.835366</td>\n",
       "      <td>0.856707</td>\n",
       "      <td>0.844118</td>\n",
       "      <td>0.791176</td>\n",
       "      <td>0.839706</td>\n",
       "      <td>0.836765</td>\n",
       "      <td>0.806402</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>0.727941</td>\n",
       "      <td>0.770579</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       support vector machines{'C': 1}  \\\n",
       "count                        50.000000   \n",
       "mean                          0.739769   \n",
       "std                           0.056570   \n",
       "min                           0.613235   \n",
       "25%                           0.711029   \n",
       "50%                           0.743275   \n",
       "75%                           0.774632   \n",
       "max                           0.897059   \n",
       "\n",
       "       random forest{'criterion': 'entropy', 'n_estimators': 500}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.731725            \n",
       "std                                             0.057517            \n",
       "min                                             0.600735            \n",
       "25%                                             0.701639            \n",
       "50%                                             0.739136            \n",
       "75%                                             0.769853            \n",
       "max                                             0.870588            \n",
       "\n",
       "       support vector machines{'C': 0.1}  support vector machines{'C': 0.01}  \\\n",
       "count                          50.000000                           50.000000   \n",
       "mean                            0.735853                            0.735799   \n",
       "std                             0.048290                            0.055810   \n",
       "min                             0.626471                            0.617647   \n",
       "25%                             0.701610                            0.697426   \n",
       "50%                             0.735294                            0.734559   \n",
       "75%                             0.775000                            0.770588   \n",
       "max                             0.820588                            0.860294   \n",
       "\n",
       "       random forest{'criterion': 'gini', 'n_estimators': 500}  \\\n",
       "count                                          50.000000         \n",
       "mean                                            0.726879         \n",
       "std                                             0.063630         \n",
       "min                                             0.564024         \n",
       "25%                                             0.688215         \n",
       "50%                                             0.732721         \n",
       "75%                                             0.765074         \n",
       "max                                             0.874265         \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}  \\\n",
       "count                                          50.000000     \n",
       "mean                                            0.689289     \n",
       "std                                             0.060079     \n",
       "min                                             0.514706     \n",
       "25%                                             0.648399     \n",
       "50%                                             0.708824     \n",
       "75%                                             0.734559     \n",
       "max                                             0.776471     \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.690042            \n",
       "std                                             0.073649            \n",
       "min                                             0.482353            \n",
       "25%                                             0.636029            \n",
       "50%                                             0.703605            \n",
       "75%                                             0.743221            \n",
       "max                                             0.835366            \n",
       "\n",
       "       support vector machines{'C': 10}  naive bayes{}  \\\n",
       "count                         50.000000      50.000000   \n",
       "mean                           0.693569       0.684504   \n",
       "std                            0.066492       0.076228   \n",
       "min                            0.538110       0.502206   \n",
       "25%                            0.653309       0.618936   \n",
       "50%                            0.693382       0.690441   \n",
       "75%                            0.728842       0.740441   \n",
       "max                            0.856707       0.844118   \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}  \\\n",
       "count                                          50.000000        \n",
       "mean                                            0.679984        \n",
       "std                                             0.060335        \n",
       "min                                             0.536765        \n",
       "25%                                             0.633456        \n",
       "50%                                             0.688971        \n",
       "75%                                             0.719118        \n",
       "max                                             0.791176        \n",
       "\n",
       "       XG boost{'use_label_encoder': False}  Light GBM{}  \\\n",
       "count                             50.000000    50.000000   \n",
       "mean                               0.680801     0.684174   \n",
       "std                                0.068725     0.072771   \n",
       "min                                0.525000     0.457353   \n",
       "25%                                0.638971     0.644485   \n",
       "50%                                0.688235     0.684451   \n",
       "75%                                0.723162     0.727941   \n",
       "max                                0.839706     0.836765   \n",
       "\n",
       "       k neighbors{'n_neighbors': 5}  k neighbors{'n_neighbors': 3}  \\\n",
       "count                      50.000000                      50.000000   \n",
       "mean                        0.643374                       0.615450   \n",
       "std                         0.072418                       0.071068   \n",
       "min                         0.478676                       0.450000   \n",
       "25%                         0.605882                       0.579044   \n",
       "50%                         0.647059                       0.608528   \n",
       "75%                         0.690441                       0.669669   \n",
       "max                         0.806402                       0.730882   \n",
       "\n",
       "       decision tree{'criterion': 'entropy'}  \\\n",
       "count                              50.000000   \n",
       "mean                                0.576135   \n",
       "std                                 0.063252   \n",
       "min                                 0.438235   \n",
       "25%                                 0.527094   \n",
       "50%                                 0.576838   \n",
       "75%                                 0.610294   \n",
       "max                                 0.727941   \n",
       "\n",
       "       decision tree{'criterion': 'gini'}  elastic net{'max_iter': 10000}  \n",
       "count                           50.000000                            50.0  \n",
       "mean                             0.582048                             0.5  \n",
       "std                              0.070848                             0.0  \n",
       "min                              0.442647                             0.5  \n",
       "25%                              0.539652                             0.5  \n",
       "50%                              0.566544                             0.5  \n",
       "75%                              0.609191                             0.5  \n",
       "max                              0.770579                             0.5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_screen_nomt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "266fcb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.8205882352941176\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.8691176470588236\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__C': 0.1, 'classifier__gamma': 'scale', 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__C': 0.1, 'classifier__gamma': 'scale', 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6985294117647058\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.20588235294117646\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.7378048780487805\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.869118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.820588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.737805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__gamma': 's...</td>\n",
       "      <td>0.698529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__gamma': '...</td>\n",
       "      <td>0.205882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__C': 0.1, 'classifier__gamma': 'a...  0.869118\n",
       "1  {'classifier__C': 0.1, 'classifier__gamma': 'a...  0.820588\n",
       "2  {'classifier__C': 1.0, 'classifier__gamma': 'a...  0.737805\n",
       "3  {'classifier__C': 0.1, 'classifier__gamma': 's...  0.698529\n",
       "4  {'classifier__C': 0.01, 'classifier__gamma': '...  0.205882"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune SVM\n",
    "\n",
    "fname_text = 'experiments/fav_functional_status/no_mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/fav_functional_status/no_mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = SVC(probability = True), param_grid = svm_grid, X_train = X_train_nomt, \n",
    "            y_train = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4be67994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7014705882352941\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7970588235294118\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7705882352941176\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6588235294117647\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.6615853658536586\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__max_depth': 100.0, 'classifier__...</td>\n",
       "      <td>0.797059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__max_depth': 80.0, 'classifier__m...</td>\n",
       "      <td>0.770588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__max_depth': 100.0, 'classifier__...</td>\n",
       "      <td>0.701471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__max_depth': 100.0, 'classifier__...</td>\n",
       "      <td>0.661585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__max_depth': 80.0, 'classifier__m...</td>\n",
       "      <td>0.658824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__max_depth': 100.0, 'classifier__...  0.797059\n",
       "1  {'classifier__max_depth': 80.0, 'classifier__m...  0.770588\n",
       "2  {'classifier__max_depth': 100.0, 'classifier__...  0.701471\n",
       "3  {'classifier__max_depth': 100.0, 'classifier__...  0.661585\n",
       "4  {'classifier__max_depth': 80.0, 'classifier__m...  0.658824"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune RF\n",
    "\n",
    "fname_text = 'experiments/fav_functional_status/no_mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/fav_functional_status/no_mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = RandomForestClassifier(), param_grid = rf_grid, X_train = X_train_nomt, \n",
    "            y_train = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acd33cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__beta_1': 0.9, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (10, 10, 10), 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.9, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (10, 10, 10), 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6367647058823529\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__beta_1': 0.3, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (10,), 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.3, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (10,), 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6455882352941176\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7323529411764707\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__beta_1': 0.9, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (10, 10, 10), 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__beta_1': 0.9, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (10, 10, 10), 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.6794117647058824\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 60.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 60.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.8292682926829268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__beta_1': 0.6000000000000001, 'cl...</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__beta_1': 0.6000000000000001, 'cl...</td>\n",
       "      <td>0.732353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__beta_1': 0.9, 'classifier__beta_...</td>\n",
       "      <td>0.679412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__beta_1': 0.3, 'classifier__beta_...</td>\n",
       "      <td>0.645588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__beta_1': 0.9, 'classifier__beta_...</td>\n",
       "      <td>0.636765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__beta_1': 0.6000000000000001, 'cl...  0.829268\n",
       "1  {'classifier__beta_1': 0.6000000000000001, 'cl...  0.732353\n",
       "2  {'classifier__beta_1': 0.9, 'classifier__beta_...  0.679412\n",
       "3  {'classifier__beta_1': 0.3, 'classifier__beta_...  0.645588\n",
       "4  {'classifier__beta_1': 0.9, 'classifier__beta_...  0.636765"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune MLP\n",
    "\n",
    "fname_text = 'experiments/fav_functional_status/no_mt_data/mlp_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/fav_functional_status/no_mt_data/mlp_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = MLPClassifier(max_iter = 10000), param_grid = mlp_grid, X_train = X_train_nomt, \n",
    "            y_train = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d9a088bc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for RandomForestClassifier(max_depth=100, min_samples_leaf=2, min_samples_split=5,\n",
      "                       n_estimators=500)\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=0)),\n",
       "                                                                  ('variance_threshold',\n",
       "                                                                   VarianceThreshold(threshold=0.4)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'time_to_arr']),\n",
       "                                                 ('...\n",
       "                                                                   SelectPercentile(score_func=<function chi2 at 0x7fb3db3df670>))]),\n",
       "                                                  ['hypox', 'wake_up',\n",
       "                                                   'seizure', 'transfer', 'tpa',\n",
       "                                                   'stroke_etiol', 'sex',\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('SMOTE', SMOTE()),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_depth=100, min_samples_leaf=2,\n",
       "                                        min_samples_split=5,\n",
       "                                        n_estimators=500))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain best model on entire training set and save model\n",
    "\n",
    "retrain_save(X = X_train_nomt, \n",
    "             y = y_train, \n",
    "             percentile = 10, \n",
    "             threshold = 0.4, \n",
    "             final_model = RandomForestClassifier(max_depth = 100, min_samples_leaf = 2, min_samples_split = 5, \n",
    "                                                  n_estimators = 500), \n",
    "             fname = 'models/fav_functional_status/no_mt_data/final_rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7085cb01",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=42)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'time_to_arr']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('ordinal '\n",
       "                                                                   'encoder',\n",
       "                                                                   OrdinalEncoder...\n",
       "                                                                  ('one hot '\n",
       "                                                                   'encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['hypox', 'wake_up',\n",
       "                                                   'seizure', 'transfer', 'tpa',\n",
       "                                                   'stroke_etiol', 'sex',\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('logistic regression',\n",
       "                 LogisticRegression(max_iter=10000, penalty='none',\n",
       "                                    random_state=42))])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train LR model on entire training set and save model\n",
    "\n",
    "train_save_lr(X = X_train_nomt, \n",
    "             y = y_train, \n",
    "             fname = 'models/fav_functional_status/no_mt_data/final_lr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c24e8c1",
   "metadata": {},
   "source": [
    "### 3. Mortality prediction - with MT data\n",
    "Model training includes variables from mechanical thrombectomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bf794177",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mt_mort = pd.read_pickle('transformed_datasets/mortality/mt_data/X_train_trans_mt.pkl')\n",
    "y_train_mort = np.load('transformed_datasets/mortality/y_train_trans.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c9ca98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline logistic regression model with CV using 5 splits and 10 repeats\n",
      "Mean AUC for baseline logistic regression model: 0.7086845584083435 +/- 0.07527547643934501\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline LR model\n",
    "\n",
    "pipe_lr_mt_mort, scores_lr_mt_mort = baseline_lr(X_train = X_train_mt_mort, y_train = y_train_mort, n_splits = 5, \n",
    "                                                 n_repeats = 10, scoring = 'roc_auc', \n",
    "                                                 fname = 'experiments/mortality/mt_data/baseline_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bc1fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating elastic net...\n",
      "Evaluating decision tree...\n",
      "Evaluating random forest...\n",
      "Evaluating k neighbors...\n",
      "Evaluating naive bayes...\n",
      "Evaluating support vector machines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/impute/_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/impute/_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XG boost...\n",
      "Evaluating Light GBM...\n",
      "Evaluating MLP...\n"
     ]
    }
   ],
   "source": [
    "# screen models\n",
    "\n",
    "fname = 'experiments/mortality/mt_data/init_screening_summary' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_df = 'experiments/mortality/mt_data/init_screening_results' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl' \n",
    "\n",
    "init_screen_mt = screen_models(models = models, score = 'roc_auc', X_train = X_train_mt_mort, \n",
    "                               y_train = y_train_mort, fname = fname, fname_df = fname_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "898274b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support vector machines{'C': 1}</th>\n",
       "      <th>support vector machines{'C': 0.01}</th>\n",
       "      <th>support vector machines{'C': 0.1}</th>\n",
       "      <th>random forest{'criterion': 'gini', 'n_estimators': 500}</th>\n",
       "      <th>random forest{'criterion': 'entropy', 'n_estimators': 500}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}</th>\n",
       "      <th>naive bayes{}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}</th>\n",
       "      <th>support vector machines{'C': 10}</th>\n",
       "      <th>Light GBM{}</th>\n",
       "      <th>XG boost{'use_label_encoder': False}</th>\n",
       "      <th>k neighbors{'n_neighbors': 5}</th>\n",
       "      <th>k neighbors{'n_neighbors': 3}</th>\n",
       "      <th>decision tree{'criterion': 'gini'}</th>\n",
       "      <th>decision tree{'criterion': 'entropy'}</th>\n",
       "      <th>elastic net{'max_iter': 10000}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.745657</td>\n",
       "      <td>0.739790</td>\n",
       "      <td>0.745521</td>\n",
       "      <td>0.721038</td>\n",
       "      <td>0.723308</td>\n",
       "      <td>0.696333</td>\n",
       "      <td>0.700411</td>\n",
       "      <td>0.689227</td>\n",
       "      <td>0.683274</td>\n",
       "      <td>0.675561</td>\n",
       "      <td>0.680922</td>\n",
       "      <td>0.673149</td>\n",
       "      <td>0.614134</td>\n",
       "      <td>0.601035</td>\n",
       "      <td>0.581071</td>\n",
       "      <td>0.565810</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.051199</td>\n",
       "      <td>0.067034</td>\n",
       "      <td>0.058614</td>\n",
       "      <td>0.051313</td>\n",
       "      <td>0.066613</td>\n",
       "      <td>0.067169</td>\n",
       "      <td>0.070199</td>\n",
       "      <td>0.062833</td>\n",
       "      <td>0.067031</td>\n",
       "      <td>0.064342</td>\n",
       "      <td>0.056569</td>\n",
       "      <td>0.059451</td>\n",
       "      <td>0.067241</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.061452</td>\n",
       "      <td>0.057465</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.638107</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.611688</td>\n",
       "      <td>0.620205</td>\n",
       "      <td>0.589610</td>\n",
       "      <td>0.498721</td>\n",
       "      <td>0.537084</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.552430</td>\n",
       "      <td>0.516883</td>\n",
       "      <td>0.568831</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.429870</td>\n",
       "      <td>0.437662</td>\n",
       "      <td>0.416880</td>\n",
       "      <td>0.433766</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.714194</td>\n",
       "      <td>0.689935</td>\n",
       "      <td>0.706035</td>\n",
       "      <td>0.681006</td>\n",
       "      <td>0.681006</td>\n",
       "      <td>0.662084</td>\n",
       "      <td>0.653453</td>\n",
       "      <td>0.652929</td>\n",
       "      <td>0.631625</td>\n",
       "      <td>0.637788</td>\n",
       "      <td>0.638747</td>\n",
       "      <td>0.636039</td>\n",
       "      <td>0.568039</td>\n",
       "      <td>0.559857</td>\n",
       "      <td>0.543019</td>\n",
       "      <td>0.528453</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.756459</td>\n",
       "      <td>0.748701</td>\n",
       "      <td>0.743606</td>\n",
       "      <td>0.736144</td>\n",
       "      <td>0.718990</td>\n",
       "      <td>0.703964</td>\n",
       "      <td>0.698456</td>\n",
       "      <td>0.692966</td>\n",
       "      <td>0.690703</td>\n",
       "      <td>0.687013</td>\n",
       "      <td>0.681169</td>\n",
       "      <td>0.675192</td>\n",
       "      <td>0.626279</td>\n",
       "      <td>0.606920</td>\n",
       "      <td>0.590521</td>\n",
       "      <td>0.567208</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.779194</td>\n",
       "      <td>0.785166</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.761509</td>\n",
       "      <td>0.775889</td>\n",
       "      <td>0.735614</td>\n",
       "      <td>0.765584</td>\n",
       "      <td>0.735774</td>\n",
       "      <td>0.739286</td>\n",
       "      <td>0.716290</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.718958</td>\n",
       "      <td>0.657245</td>\n",
       "      <td>0.640870</td>\n",
       "      <td>0.627877</td>\n",
       "      <td>0.605408</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.855499</td>\n",
       "      <td>0.897403</td>\n",
       "      <td>0.823377</td>\n",
       "      <td>0.883632</td>\n",
       "      <td>0.864450</td>\n",
       "      <td>0.819693</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.805627</td>\n",
       "      <td>0.787724</td>\n",
       "      <td>0.808184</td>\n",
       "      <td>0.812987</td>\n",
       "      <td>0.768831</td>\n",
       "      <td>0.737212</td>\n",
       "      <td>0.700767</td>\n",
       "      <td>0.715473</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       support vector machines{'C': 1}  support vector machines{'C': 0.01}  \\\n",
       "count                        50.000000                           50.000000   \n",
       "mean                          0.745657                            0.739790   \n",
       "std                           0.051199                            0.067034   \n",
       "min                           0.638107                            0.545455   \n",
       "25%                           0.714194                            0.689935   \n",
       "50%                           0.756459                            0.748701   \n",
       "75%                           0.779194                            0.785166   \n",
       "max                           0.847826                            0.855499   \n",
       "\n",
       "       support vector machines{'C': 0.1}  \\\n",
       "count                          50.000000   \n",
       "mean                            0.745521   \n",
       "std                             0.058614   \n",
       "min                             0.611688   \n",
       "25%                             0.706035   \n",
       "50%                             0.743606   \n",
       "75%                             0.784091   \n",
       "max                             0.897403   \n",
       "\n",
       "       random forest{'criterion': 'gini', 'n_estimators': 500}  \\\n",
       "count                                          50.000000         \n",
       "mean                                            0.721038         \n",
       "std                                             0.051313         \n",
       "min                                             0.620205         \n",
       "25%                                             0.681006         \n",
       "50%                                             0.736144         \n",
       "75%                                             0.761509         \n",
       "max                                             0.823377         \n",
       "\n",
       "       random forest{'criterion': 'entropy', 'n_estimators': 500}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.723308            \n",
       "std                                             0.066613            \n",
       "min                                             0.589610            \n",
       "25%                                             0.681006            \n",
       "50%                                             0.718990            \n",
       "75%                                             0.775889            \n",
       "max                                             0.883632            \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}  \\\n",
       "count                                          50.000000     \n",
       "mean                                            0.696333     \n",
       "std                                             0.067169     \n",
       "min                                             0.498721     \n",
       "25%                                             0.662084     \n",
       "50%                                             0.703964     \n",
       "75%                                             0.735614     \n",
       "max                                             0.864450     \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}  naive bayes{}  \\\n",
       "count                                          50.000000           50.000000   \n",
       "mean                                            0.700411            0.689227   \n",
       "std                                             0.070199            0.062833   \n",
       "min                                             0.537084            0.557143   \n",
       "25%                                             0.653453            0.652929   \n",
       "50%                                             0.698456            0.692966   \n",
       "75%                                             0.765584            0.735774   \n",
       "max                                             0.819693            0.827273   \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.683274            \n",
       "std                                             0.067031            \n",
       "min                                             0.552430            \n",
       "25%                                             0.631625            \n",
       "50%                                             0.690703            \n",
       "75%                                             0.739286            \n",
       "max                                             0.805627            \n",
       "\n",
       "       support vector machines{'C': 10}  Light GBM{}  \\\n",
       "count                         50.000000    50.000000   \n",
       "mean                           0.675561     0.680922   \n",
       "std                            0.064342     0.056569   \n",
       "min                            0.516883     0.568831   \n",
       "25%                            0.637788     0.638747   \n",
       "50%                            0.687013     0.681169   \n",
       "75%                            0.716290     0.729545   \n",
       "max                            0.787724     0.808184   \n",
       "\n",
       "       XG boost{'use_label_encoder': False}  k neighbors{'n_neighbors': 5}  \\\n",
       "count                             50.000000                      50.000000   \n",
       "mean                               0.673149                       0.614134   \n",
       "std                                0.059451                       0.067241   \n",
       "min                                0.528571                       0.429870   \n",
       "25%                                0.636039                       0.568039   \n",
       "50%                                0.675192                       0.626279   \n",
       "75%                                0.718958                       0.657245   \n",
       "max                                0.812987                       0.768831   \n",
       "\n",
       "       k neighbors{'n_neighbors': 3}  decision tree{'criterion': 'gini'}  \\\n",
       "count                      50.000000                           50.000000   \n",
       "mean                        0.601035                            0.581071   \n",
       "std                         0.069200                            0.061452   \n",
       "min                         0.437662                            0.416880   \n",
       "25%                         0.559857                            0.543019   \n",
       "50%                         0.606920                            0.590521   \n",
       "75%                         0.640870                            0.627877   \n",
       "max                         0.737212                            0.700767   \n",
       "\n",
       "       decision tree{'criterion': 'entropy'}  elastic net{'max_iter': 10000}  \n",
       "count                              50.000000                            50.0  \n",
       "mean                                0.565810                             0.5  \n",
       "std                                 0.057465                             0.0  \n",
       "min                                 0.433766                             0.5  \n",
       "25%                                 0.528453                             0.5  \n",
       "50%                                 0.567208                             0.5  \n",
       "75%                                 0.605408                             0.5  \n",
       "max                                 0.715473                             0.5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_screen_mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52b092dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.4772727272727273\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7298701298701299\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.8081841432225063\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.22378516624040923\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.600383631713555\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.808184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.729870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.600384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__gamma': '...</td>\n",
       "      <td>0.477273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__gamma': '...</td>\n",
       "      <td>0.223785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__C': 0.1, 'classifier__gamma': 'a...  0.808184\n",
       "1  {'classifier__C': 0.1, 'classifier__gamma': 'a...  0.729870\n",
       "2  {'classifier__C': 0.1, 'classifier__gamma': 'a...  0.600384\n",
       "3  {'classifier__C': 0.01, 'classifier__gamma': '...  0.477273\n",
       "4  {'classifier__C': 0.01, 'classifier__gamma': '...  0.223785"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune SVM\n",
    "\n",
    "fname_text = 'experiments/mortality/mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/mortality/mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = SVC(probability = True), param_grid = svm_grid, X_train = X_train_mt_mort, \n",
    "            y_train = y_train_mort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6516ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7025974025974026\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.6857142857142857\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 60.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 60.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7941176470588236\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7097186700767264\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7276214833759591\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__max_depth': 80.0, 'classifier__m...</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__max_depth': 80.0, 'classifier__m...</td>\n",
       "      <td>0.727621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__max_depth': 60.0, 'classifier__m...</td>\n",
       "      <td>0.709719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__max_depth': 80.0, 'classifier__m...</td>\n",
       "      <td>0.702597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__max_depth': 100.0, 'classifier__...</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__max_depth': 80.0, 'classifier__m...  0.794118\n",
       "1  {'classifier__max_depth': 80.0, 'classifier__m...  0.727621\n",
       "2  {'classifier__max_depth': 60.0, 'classifier__m...  0.709719\n",
       "3  {'classifier__max_depth': 80.0, 'classifier__m...  0.702597\n",
       "4  {'classifier__max_depth': 100.0, 'classifier__...  0.685714"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune RF\n",
    "\n",
    "fname_text = 'experiments/mortality/mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/mortality/mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = RandomForestClassifier(), param_grid = rf_grid, X_train = X_train_mt_mort, \n",
    "            y_train = y_train_mort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfd16df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__beta_1': 0.3, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (10, 10), 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.3, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (10, 10), 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6935064935064936\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__beta_1': 0.3, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (30, 30), 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__beta_1': 0.3, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (30, 30), 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.7350649350649351\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__beta_1': 0.9, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (10, 10), 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.9, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (10, 10), 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6150895140664961\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__beta_1': 0.9, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (10,), 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__beta_1': 0.9, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (10,), 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.6534526854219949\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (10, 10), 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (10, 10), 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.5677749360613811\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__beta_1': 0.3, 'classifier__beta_...</td>\n",
       "      <td>0.735065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__beta_1': 0.3, 'classifier__beta_...</td>\n",
       "      <td>0.693506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__beta_1': 0.9, 'classifier__beta_...</td>\n",
       "      <td>0.653453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__beta_1': 0.9, 'classifier__beta_...</td>\n",
       "      <td>0.615090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__beta_1': 0.6000000000000001, 'cl...</td>\n",
       "      <td>0.567775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__beta_1': 0.3, 'classifier__beta_...  0.735065\n",
       "1  {'classifier__beta_1': 0.3, 'classifier__beta_...  0.693506\n",
       "2  {'classifier__beta_1': 0.9, 'classifier__beta_...  0.653453\n",
       "3  {'classifier__beta_1': 0.9, 'classifier__beta_...  0.615090\n",
       "4  {'classifier__beta_1': 0.6000000000000001, 'cl...  0.567775"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune MLP\n",
    "\n",
    "fname_text = 'experiments/mortality/mt_data/mlp_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/mortality/mt_data/mlp_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = MLPClassifier(max_iter = 10000), param_grid = mlp_grid, X_train = X_train_mt_mort, \n",
    "            y_train = y_train_mort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a85c4ec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for RandomForestClassifier(max_depth=80, min_samples_split=10, n_estimators=500)\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=0)),\n",
       "                                                                  ('variance_threshold',\n",
       "                                                                   VarianceThreshold(threshold=0.6)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'heparin',\n",
       "                                                   'num_pas...\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'ptas',\n",
       "                                                   'stent_ret', 'aspiration',\n",
       "                                                   'first_pass_reperf',\n",
       "                                                   'procedure_ap', 'gen_anes',\n",
       "                                                   'hypoten_mt', 'tici_success',\n",
       "                                                   'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('SMOTE', SMOTE()),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_depth=80, min_samples_split=10,\n",
       "                                        n_estimators=500))])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain best model on entire training set and save model\n",
    "\n",
    "retrain_save(X = X_train_mt_mort, \n",
    "             y = y_train_mort, \n",
    "             percentile = 60, \n",
    "             threshold = 0.6, \n",
    "             final_model = RandomForestClassifier(max_depth = 80, min_samples_leaf = 1, min_samples_split = 10, \n",
    "                                                 n_estimators = 500), \n",
    "             fname = 'models/mortality/mt_data/final_rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d7b33a99",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=42)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'heparin',\n",
       "                                                   'num_pass', 'fluoro_time',\n",
       "                                                   'time_to_arr',\n",
       "                                                   'time_to_puncture',\n",
       "                                                   'time...\n",
       "                                                   'stroke_etiol', 'sex',\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'ptas',\n",
       "                                                   'stent_ret', 'aspiration',\n",
       "                                                   'first_pass_reperf',\n",
       "                                                   'procedure_ap', 'gen_anes',\n",
       "                                                   'hypoten_mt', 'tici_success',\n",
       "                                                   'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('logistic regression',\n",
       "                 LogisticRegression(max_iter=10000, penalty='none',\n",
       "                                    random_state=42))])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train LR model on entire training set and save model\n",
    "\n",
    "train_save_lr(X = X_train_mt_mort, \n",
    "             y = y_train_mort, \n",
    "             fname = 'models/mortality/mt_data/final_lr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8455a81",
   "metadata": {},
   "source": [
    "### 4. Mortality prediction - without MT data\n",
    "Model training does not include variables from mechanical thrombectomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40a4cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nomt_mort = pd.read_pickle('transformed_datasets/mortality/no_mt_data/X_train_trans_nomt.pkl')\n",
    "y_train_mort = np.load('transformed_datasets/mortality/y_train_trans.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42597a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline logistic regression model with CV using 5 splits and 10 repeats\n",
      "Mean AUC for baseline logistic regression model: 0.7172533962201483 +/- 0.06451499139163538\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline LR model\n",
    "\n",
    "pipe_lr_nomt_mort, scores_lr_nomt_mort = baseline_lr(X_train = X_train_nomt_mort, y_train = y_train_mort, \n",
    "                                                     n_splits = 5, n_repeats = 10, scoring = 'roc_auc', \n",
    "                                                 fname = 'experiments/mortality/no_mt_data/baseline_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1defc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating elastic net...\n",
      "Evaluating decision tree...\n",
      "Evaluating random forest...\n",
      "Evaluating k neighbors...\n",
      "Evaluating naive bayes...\n",
      "Evaluating support vector machines...\n",
      "Evaluating XG boost...\n",
      "Evaluating Light GBM...\n",
      "Evaluating MLP...\n"
     ]
    }
   ],
   "source": [
    "# screen models\n",
    "\n",
    "fname = 'experiments/mortality/no_mt_data/init_screening_summary' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_df = 'experiments/mortality/no_mt_data/init_screening_results' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl' \n",
    "\n",
    "init_screen_nomt = screen_models(models = models, score = 'roc_auc', X_train = X_train_nomt_mort, \n",
    "                               y_train = y_train_mort, fname = fname, fname_df = fname_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4f9230e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support vector machines{'C': 1}</th>\n",
       "      <th>random forest{'criterion': 'gini', 'n_estimators': 500}</th>\n",
       "      <th>support vector machines{'C': 0.1}</th>\n",
       "      <th>random forest{'criterion': 'entropy', 'n_estimators': 500}</th>\n",
       "      <th>support vector machines{'C': 0.01}</th>\n",
       "      <th>naive bayes{}</th>\n",
       "      <th>Light GBM{}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}</th>\n",
       "      <th>support vector machines{'C': 10}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}</th>\n",
       "      <th>XG boost{'use_label_encoder': False}</th>\n",
       "      <th>k neighbors{'n_neighbors': 5}</th>\n",
       "      <th>k neighbors{'n_neighbors': 3}</th>\n",
       "      <th>decision tree{'criterion': 'gini'}</th>\n",
       "      <th>decision tree{'criterion': 'entropy'}</th>\n",
       "      <th>elastic net{'max_iter': 10000}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.741238</td>\n",
       "      <td>0.729185</td>\n",
       "      <td>0.735184</td>\n",
       "      <td>0.728952</td>\n",
       "      <td>0.734906</td>\n",
       "      <td>0.700698</td>\n",
       "      <td>0.678547</td>\n",
       "      <td>0.664485</td>\n",
       "      <td>0.670452</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.668774</td>\n",
       "      <td>0.671861</td>\n",
       "      <td>0.664241</td>\n",
       "      <td>0.627415</td>\n",
       "      <td>0.586481</td>\n",
       "      <td>0.566081</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.049287</td>\n",
       "      <td>0.072826</td>\n",
       "      <td>0.067367</td>\n",
       "      <td>0.055160</td>\n",
       "      <td>0.061490</td>\n",
       "      <td>0.075322</td>\n",
       "      <td>0.061403</td>\n",
       "      <td>0.065246</td>\n",
       "      <td>0.060550</td>\n",
       "      <td>0.051789</td>\n",
       "      <td>0.068489</td>\n",
       "      <td>0.054594</td>\n",
       "      <td>0.062440</td>\n",
       "      <td>0.073552</td>\n",
       "      <td>0.054524</td>\n",
       "      <td>0.064239</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.632992</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0.592072</td>\n",
       "      <td>0.621483</td>\n",
       "      <td>0.583120</td>\n",
       "      <td>0.530691</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.517903</td>\n",
       "      <td>0.515345</td>\n",
       "      <td>0.568831</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.429870</td>\n",
       "      <td>0.474425</td>\n",
       "      <td>0.393506</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.713875</td>\n",
       "      <td>0.672890</td>\n",
       "      <td>0.693506</td>\n",
       "      <td>0.696928</td>\n",
       "      <td>0.703792</td>\n",
       "      <td>0.648377</td>\n",
       "      <td>0.638747</td>\n",
       "      <td>0.635065</td>\n",
       "      <td>0.640903</td>\n",
       "      <td>0.645130</td>\n",
       "      <td>0.626598</td>\n",
       "      <td>0.643588</td>\n",
       "      <td>0.629822</td>\n",
       "      <td>0.583760</td>\n",
       "      <td>0.554668</td>\n",
       "      <td>0.518831</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.742327</td>\n",
       "      <td>0.736793</td>\n",
       "      <td>0.735934</td>\n",
       "      <td>0.734015</td>\n",
       "      <td>0.727457</td>\n",
       "      <td>0.694255</td>\n",
       "      <td>0.682864</td>\n",
       "      <td>0.679114</td>\n",
       "      <td>0.677749</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.673360</td>\n",
       "      <td>0.664319</td>\n",
       "      <td>0.662404</td>\n",
       "      <td>0.634049</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.570332</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.767006</td>\n",
       "      <td>0.783644</td>\n",
       "      <td>0.786125</td>\n",
       "      <td>0.763584</td>\n",
       "      <td>0.784329</td>\n",
       "      <td>0.741973</td>\n",
       "      <td>0.729962</td>\n",
       "      <td>0.705243</td>\n",
       "      <td>0.707801</td>\n",
       "      <td>0.719949</td>\n",
       "      <td>0.713555</td>\n",
       "      <td>0.711957</td>\n",
       "      <td>0.703921</td>\n",
       "      <td>0.669318</td>\n",
       "      <td>0.629870</td>\n",
       "      <td>0.618766</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.875959</td>\n",
       "      <td>0.894805</td>\n",
       "      <td>0.854220</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.907928</td>\n",
       "      <td>0.785166</td>\n",
       "      <td>0.786445</td>\n",
       "      <td>0.796104</td>\n",
       "      <td>0.773657</td>\n",
       "      <td>0.815584</td>\n",
       "      <td>0.776623</td>\n",
       "      <td>0.797954</td>\n",
       "      <td>0.783117</td>\n",
       "      <td>0.708440</td>\n",
       "      <td>0.672634</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       support vector machines{'C': 1}  \\\n",
       "count                        50.000000   \n",
       "mean                          0.741238   \n",
       "std                           0.049287   \n",
       "min                           0.632992   \n",
       "25%                           0.713875   \n",
       "50%                           0.742327   \n",
       "75%                           0.767006   \n",
       "max                           0.872727   \n",
       "\n",
       "       random forest{'criterion': 'gini', 'n_estimators': 500}  \\\n",
       "count                                          50.000000         \n",
       "mean                                            0.729185         \n",
       "std                                             0.072826         \n",
       "min                                             0.554545         \n",
       "25%                                             0.672890         \n",
       "50%                                             0.736793         \n",
       "75%                                             0.783644         \n",
       "max                                             0.875959         \n",
       "\n",
       "       support vector machines{'C': 0.1}  \\\n",
       "count                          50.000000   \n",
       "mean                            0.735184   \n",
       "std                             0.067367   \n",
       "min                             0.592072   \n",
       "25%                             0.693506   \n",
       "50%                             0.735934   \n",
       "75%                             0.786125   \n",
       "max                             0.894805   \n",
       "\n",
       "       random forest{'criterion': 'entropy', 'n_estimators': 500}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.728952            \n",
       "std                                             0.055160            \n",
       "min                                             0.621483            \n",
       "25%                                             0.696928            \n",
       "50%                                             0.734015            \n",
       "75%                                             0.763584            \n",
       "max                                             0.854220            \n",
       "\n",
       "       support vector machines{'C': 0.01}  naive bayes{}  Light GBM{}  \\\n",
       "count                           50.000000      50.000000    50.000000   \n",
       "mean                             0.734906       0.700698     0.678547   \n",
       "std                              0.061490       0.075322     0.061403   \n",
       "min                              0.583120       0.530691     0.514286   \n",
       "25%                              0.703792       0.648377     0.638747   \n",
       "50%                              0.727457       0.694255     0.682864   \n",
       "75%                              0.784329       0.741973     0.729962   \n",
       "max                              0.869565       0.907928     0.785166   \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.664485            \n",
       "std                                             0.065246            \n",
       "min                                             0.517903            \n",
       "25%                                             0.635065            \n",
       "50%                                             0.679114            \n",
       "75%                                             0.705243            \n",
       "max                                             0.786445            \n",
       "\n",
       "       support vector machines{'C': 10}  \\\n",
       "count                         50.000000   \n",
       "mean                           0.670452   \n",
       "std                            0.060550   \n",
       "min                            0.515345   \n",
       "25%                            0.640903   \n",
       "50%                            0.677749   \n",
       "75%                            0.707801   \n",
       "max                            0.796104   \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}  \\\n",
       "count                                          50.000000        \n",
       "mean                                            0.678682        \n",
       "std                                             0.051789        \n",
       "min                                             0.568831        \n",
       "25%                                             0.645130        \n",
       "50%                                             0.676471        \n",
       "75%                                             0.719949        \n",
       "max                                             0.773657        \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}  \\\n",
       "count                                          50.000000     \n",
       "mean                                            0.668774     \n",
       "std                                             0.068489     \n",
       "min                                             0.521739     \n",
       "25%                                             0.626598     \n",
       "50%                                             0.673360     \n",
       "75%                                             0.713555     \n",
       "max                                             0.815584     \n",
       "\n",
       "       XG boost{'use_label_encoder': False}  k neighbors{'n_neighbors': 5}  \\\n",
       "count                             50.000000                      50.000000   \n",
       "mean                               0.671861                       0.664241   \n",
       "std                                0.054594                       0.062440   \n",
       "min                                0.557143                       0.521739   \n",
       "25%                                0.643588                       0.629822   \n",
       "50%                                0.664319                       0.662404   \n",
       "75%                                0.711957                       0.703921   \n",
       "max                                0.776623                       0.797954   \n",
       "\n",
       "       k neighbors{'n_neighbors': 3}  decision tree{'criterion': 'gini'}  \\\n",
       "count                      50.000000                           50.000000   \n",
       "mean                        0.627415                            0.586481   \n",
       "std                         0.073552                            0.054524   \n",
       "min                         0.429870                            0.474425   \n",
       "25%                         0.583760                            0.554668   \n",
       "50%                         0.634049                            0.585714   \n",
       "75%                         0.669318                            0.629870   \n",
       "max                         0.783117                            0.708440   \n",
       "\n",
       "       decision tree{'criterion': 'entropy'}  elastic net{'max_iter': 10000}  \n",
       "count                              50.000000                            50.0  \n",
       "mean                                0.566081                             0.5  \n",
       "std                                 0.064239                             0.0  \n",
       "min                                 0.393506                             0.5  \n",
       "25%                                 0.518831                             0.5  \n",
       "50%                                 0.570332                             0.5  \n",
       "75%                                 0.618766                             0.5  \n",
       "max                                 0.672634                             0.5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_screen_nomt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a59e1c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.27402597402597406\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 90.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 90.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.6909090909090909\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 90.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 90.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.23145780051150897\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.6777493606138107\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.2320971867007673\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.677749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__gamma': '...</td>\n",
       "      <td>0.274026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__gamma': '...</td>\n",
       "      <td>0.232097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__gamma': '...</td>\n",
       "      <td>0.231458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__C': 1.0, 'classifier__gamma': 'a...  0.690909\n",
       "1  {'classifier__C': 0.1, 'classifier__gamma': 'a...  0.677749\n",
       "2  {'classifier__C': 0.01, 'classifier__gamma': '...  0.274026\n",
       "3  {'classifier__C': 0.01, 'classifier__gamma': '...  0.232097\n",
       "4  {'classifier__C': 0.01, 'classifier__gamma': '...  0.231458"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune SVM\n",
    "\n",
    "fname_text = 'experiments/mortality/no_mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/mortality/no_mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = SVC(probability = True), param_grid = svm_grid, X_train = X_train_nomt_mort, \n",
    "            y_train = y_train_mort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b987806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__max_depth': 20.0, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 20.0, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6090909090909091\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7987012987012987\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__max_depth': 40.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 40.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7365728900255754\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__max_depth': 40.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__max_depth': 40.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7352941176470588\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.592071611253197\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__max_depth': 60.0, 'classifier__m...</td>\n",
       "      <td>0.798701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__max_depth': 40.0, 'classifier__m...</td>\n",
       "      <td>0.736573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__max_depth': 40.0, 'classifier__m...</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__max_depth': 20.0, 'classifier__m...</td>\n",
       "      <td>0.609091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__max_depth': 100.0, 'classifier__...</td>\n",
       "      <td>0.592072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__max_depth': 60.0, 'classifier__m...  0.798701\n",
       "1  {'classifier__max_depth': 40.0, 'classifier__m...  0.736573\n",
       "2  {'classifier__max_depth': 40.0, 'classifier__m...  0.735294\n",
       "3  {'classifier__max_depth': 20.0, 'classifier__m...  0.609091\n",
       "4  {'classifier__max_depth': 100.0, 'classifier__...  0.592072"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune RF\n",
    "\n",
    "fname_text = 'experiments/mortality/no_mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/mortality/no_mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = RandomForestClassifier(), param_grid = rf_grid, X_train = X_train_nomt_mort, \n",
    "            y_train = y_train_mort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8edd3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__var_smoothing': 1e-09, 'preprocessor__cat__selector__percentile': 60.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__var_smoothing': 1e-09, 'preprocessor__cat__selector__percentile': 60.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6993506493506494\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__var_smoothing': 1.0, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__var_smoothing': 1.0, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7558441558441559\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__var_smoothing': 1.0, 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__var_smoothing': 1.0, 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.7084398976982097\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__var_smoothing': 1.0, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__var_smoothing': 1.0, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.6994884910485933\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__var_smoothing': 1e-08, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__var_smoothing': 1e-08, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.6163682864450127\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__var_smoothing': 1.0, 'preprocess...</td>\n",
       "      <td>0.755844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__var_smoothing': 1.0, 'preprocess...</td>\n",
       "      <td>0.708440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__var_smoothing': 1.0, 'preprocess...</td>\n",
       "      <td>0.699488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__var_smoothing': 1e-09, 'preproce...</td>\n",
       "      <td>0.699351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__var_smoothing': 1e-08, 'preproce...</td>\n",
       "      <td>0.616368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__var_smoothing': 1.0, 'preprocess...  0.755844\n",
       "1  {'classifier__var_smoothing': 1.0, 'preprocess...  0.708440\n",
       "2  {'classifier__var_smoothing': 1.0, 'preprocess...  0.699488\n",
       "3  {'classifier__var_smoothing': 1e-09, 'preproce...  0.699351\n",
       "4  {'classifier__var_smoothing': 1e-08, 'preproce...  0.616368"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune NB\n",
    "\n",
    "fname_text = 'experiments/mortality/no_mt_data/nb_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/mortality/no_mt_data/nb_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = GaussianNB(), param_grid = nb_grid, X_train = X_train_nomt_mort, \n",
    "            y_train = y_train_mort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65fc7ff2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for RandomForestClassifier(max_depth=60, min_samples_split=10, n_estimators=500)\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=0)),\n",
       "                                                                  ('variance_threshold',\n",
       "                                                                   VarianceThreshold(threshold=0.6)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'time_to_arr']),\n",
       "                                                 ('...\n",
       "                                                                                    score_func=<function chi2 at 0x7fb3db3df670>))]),\n",
       "                                                  ['hypox', 'wake_up',\n",
       "                                                   'seizure', 'transfer', 'tpa',\n",
       "                                                   'stroke_etiol', 'sex',\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('SMOTE', SMOTE()),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_depth=60, min_samples_split=10,\n",
       "                                        n_estimators=500))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain best model on entire training set and save model\n",
    "\n",
    "retrain_save(X = X_train_nomt_mort, \n",
    "             y = y_train_mort, \n",
    "             percentile = 20, \n",
    "             threshold = 0.6, \n",
    "             final_model = RandomForestClassifier(max_depth = 60, min_samples_leaf = 1, min_samples_split = 10, \n",
    "                                                 n_estimators = 500), \n",
    "             fname = 'models/mortality/no_mt_data/final_rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "117f6796",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=42)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'time_to_arr']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('ordinal '\n",
       "                                                                   'encoder',\n",
       "                                                                   OrdinalEncoder...\n",
       "                                                                  ('one hot '\n",
       "                                                                   'encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['hypox', 'wake_up',\n",
       "                                                   'seizure', 'transfer', 'tpa',\n",
       "                                                   'stroke_etiol', 'sex',\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('logistic regression',\n",
       "                 LogisticRegression(max_iter=10000, penalty='none',\n",
       "                                    random_state=42))])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train LR model on entire training set and save model\n",
    "\n",
    "train_save_lr(X = X_train_nomt_mort, \n",
    "             y = y_train_mort, \n",
    "             fname = 'models/mortality/no_mt_data/final_lr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4856fba",
   "metadata": {},
   "source": [
    "### 5. Death or severe disability prediction - with MT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "927235a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mt_dsd = pd.read_pickle('transformed_datasets/dsd/mt_data/X_train_trans_mt.pkl')\n",
    "y_train_dsd = np.load('transformed_datasets/dsd/y_train_trans.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6c7fcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline logistic regression model with CV using 5 splits and 10 repeats\n",
      "Mean AUC for baseline logistic regression model: 0.7564733044733045 +/- 0.05511069163625624\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline LR model\n",
    "\n",
    "pipe_lr_mt_dsd, scores_lr_mt_dsd = baseline_lr(X_train = X_train_mt_dsd, y_train = y_train_dsd, n_splits = 5, \n",
    "                                                 n_repeats = 10, scoring = 'roc_auc', \n",
    "                                                 fname = 'experiments/dsd/mt_data/baseline_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24948147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating elastic net...\n",
      "Evaluating decision tree...\n",
      "Evaluating random forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/impute/_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/impute/_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k neighbors...\n",
      "Evaluating naive bayes...\n",
      "Evaluating support vector machines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/impute/_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XG boost...\n",
      "Evaluating Light GBM...\n",
      "Evaluating MLP...\n"
     ]
    }
   ],
   "source": [
    "# screen models\n",
    "\n",
    "fname = 'experiments/dsd/mt_data/init_screening_summary' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_df = 'experiments/dsd/mt_data/init_screening_results' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl' \n",
    "\n",
    "init_screen_mt = screen_models(models = models, score = 'roc_auc', X_train = X_train_mt_dsd, \n",
    "                               y_train = y_train_dsd, fname = fname, fname_df = fname_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "420367d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support vector machines{'C': 0.1}</th>\n",
       "      <th>support vector machines{'C': 1}</th>\n",
       "      <th>support vector machines{'C': 0.01}</th>\n",
       "      <th>random forest{'criterion': 'entropy', 'n_estimators': 500}</th>\n",
       "      <th>support vector machines{'C': 10}</th>\n",
       "      <th>random forest{'criterion': 'gini', 'n_estimators': 500}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}</th>\n",
       "      <th>Light GBM{}</th>\n",
       "      <th>XG boost{'use_label_encoder': False}</th>\n",
       "      <th>k neighbors{'n_neighbors': 5}</th>\n",
       "      <th>naive bayes{}</th>\n",
       "      <th>k neighbors{'n_neighbors': 3}</th>\n",
       "      <th>decision tree{'criterion': 'entropy'}</th>\n",
       "      <th>decision tree{'criterion': 'gini'}</th>\n",
       "      <th>elastic net{'max_iter': 10000}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.767939</td>\n",
       "      <td>0.777400</td>\n",
       "      <td>0.777472</td>\n",
       "      <td>0.742439</td>\n",
       "      <td>0.750694</td>\n",
       "      <td>0.741964</td>\n",
       "      <td>0.712674</td>\n",
       "      <td>0.716121</td>\n",
       "      <td>0.706828</td>\n",
       "      <td>0.707649</td>\n",
       "      <td>0.698947</td>\n",
       "      <td>0.685750</td>\n",
       "      <td>0.676217</td>\n",
       "      <td>0.662056</td>\n",
       "      <td>0.616725</td>\n",
       "      <td>0.614753</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.072417</td>\n",
       "      <td>0.063064</td>\n",
       "      <td>0.065560</td>\n",
       "      <td>0.063575</td>\n",
       "      <td>0.054117</td>\n",
       "      <td>0.043757</td>\n",
       "      <td>0.062829</td>\n",
       "      <td>0.066173</td>\n",
       "      <td>0.071583</td>\n",
       "      <td>0.065011</td>\n",
       "      <td>0.062387</td>\n",
       "      <td>0.054579</td>\n",
       "      <td>0.060334</td>\n",
       "      <td>0.069102</td>\n",
       "      <td>0.066822</td>\n",
       "      <td>0.056164</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.637566</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.592208</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.658442</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.529101</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.567460</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.494709</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.723876</td>\n",
       "      <td>0.742587</td>\n",
       "      <td>0.736995</td>\n",
       "      <td>0.703247</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.712455</td>\n",
       "      <td>0.675758</td>\n",
       "      <td>0.657407</td>\n",
       "      <td>0.655339</td>\n",
       "      <td>0.665675</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.645972</td>\n",
       "      <td>0.651741</td>\n",
       "      <td>0.610227</td>\n",
       "      <td>0.581349</td>\n",
       "      <td>0.577679</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.776527</td>\n",
       "      <td>0.774471</td>\n",
       "      <td>0.755249</td>\n",
       "      <td>0.748353</td>\n",
       "      <td>0.742725</td>\n",
       "      <td>0.729497</td>\n",
       "      <td>0.722150</td>\n",
       "      <td>0.711640</td>\n",
       "      <td>0.706349</td>\n",
       "      <td>0.688107</td>\n",
       "      <td>0.685786</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.672078</td>\n",
       "      <td>0.614340</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.822751</td>\n",
       "      <td>0.823413</td>\n",
       "      <td>0.828193</td>\n",
       "      <td>0.785886</td>\n",
       "      <td>0.786358</td>\n",
       "      <td>0.772493</td>\n",
       "      <td>0.757738</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.759921</td>\n",
       "      <td>0.743831</td>\n",
       "      <td>0.747078</td>\n",
       "      <td>0.724495</td>\n",
       "      <td>0.702213</td>\n",
       "      <td>0.706385</td>\n",
       "      <td>0.660958</td>\n",
       "      <td>0.646807</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.891534</td>\n",
       "      <td>0.915344</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.869481</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.864935</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.887013</td>\n",
       "      <td>0.863757</td>\n",
       "      <td>0.786376</td>\n",
       "      <td>0.843915</td>\n",
       "      <td>0.877273</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.742063</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       support vector machines{'C': 0.1}  support vector machines{'C': 1}  \\\n",
       "count                          50.000000                        50.000000   \n",
       "mean                            0.767939                         0.777400   \n",
       "std                             0.072417                         0.063064   \n",
       "min                             0.532468                         0.637566   \n",
       "25%                             0.723876                         0.742587   \n",
       "50%                             0.784404                         0.776527   \n",
       "75%                             0.822751                         0.823413   \n",
       "max                             0.891534                         0.915344   \n",
       "\n",
       "       support vector machines{'C': 0.01}  \\\n",
       "count                           50.000000   \n",
       "mean                             0.777472   \n",
       "std                              0.065560   \n",
       "min                              0.590909   \n",
       "25%                              0.736995   \n",
       "50%                              0.774471   \n",
       "75%                              0.828193   \n",
       "max                              0.912698   \n",
       "\n",
       "       random forest{'criterion': 'entropy', 'n_estimators': 500}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.742439            \n",
       "std                                             0.063575            \n",
       "min                                             0.592208            \n",
       "25%                                             0.703247            \n",
       "50%                                             0.755249            \n",
       "75%                                             0.785886            \n",
       "max                                             0.869481            \n",
       "\n",
       "       support vector machines{'C': 10}  \\\n",
       "count                         50.000000   \n",
       "mean                           0.750694   \n",
       "std                            0.054117   \n",
       "min                            0.657143   \n",
       "25%                            0.712963   \n",
       "50%                            0.748353   \n",
       "75%                            0.786358   \n",
       "max                            0.872727   \n",
       "\n",
       "       random forest{'criterion': 'gini', 'n_estimators': 500}  \\\n",
       "count                                          50.000000         \n",
       "mean                                            0.741964         \n",
       "std                                             0.043757         \n",
       "min                                             0.658442         \n",
       "25%                                             0.712455         \n",
       "50%                                             0.742725         \n",
       "75%                                             0.772493         \n",
       "max                                             0.827381         \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.712674            \n",
       "std                                             0.062829            \n",
       "min                                             0.557143            \n",
       "25%                                             0.675758            \n",
       "50%                                             0.729497            \n",
       "75%                                             0.757738            \n",
       "max                                             0.831169            \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}  \\\n",
       "count                                          50.000000     \n",
       "mean                                            0.716121     \n",
       "std                                             0.066173     \n",
       "min                                             0.595238     \n",
       "25%                                             0.657407     \n",
       "50%                                             0.722150     \n",
       "75%                                             0.756944     \n",
       "max                                             0.864935     \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}  Light GBM{}  \\\n",
       "count                                          50.000000         50.000000   \n",
       "mean                                            0.706828          0.707649   \n",
       "std                                             0.071583          0.065011   \n",
       "min                                             0.529101          0.559524   \n",
       "25%                                             0.655339          0.665675   \n",
       "50%                                             0.711640          0.706349   \n",
       "75%                                             0.759921          0.743831   \n",
       "max                                             0.827273          0.887013   \n",
       "\n",
       "       XG boost{'use_label_encoder': False}  k neighbors{'n_neighbors': 5}  \\\n",
       "count                             50.000000                      50.000000   \n",
       "mean                               0.698947                       0.685750   \n",
       "std                                0.062387                       0.054579   \n",
       "min                                0.592593                       0.567460   \n",
       "25%                                0.645455                       0.645972   \n",
       "50%                                0.688107                       0.685786   \n",
       "75%                                0.747078                       0.724495   \n",
       "max                                0.863757                       0.786376   \n",
       "\n",
       "       naive bayes{}  k neighbors{'n_neighbors': 3}  \\\n",
       "count      50.000000                      50.000000   \n",
       "mean        0.676217                       0.662056   \n",
       "std         0.060334                       0.069102   \n",
       "min         0.537037                       0.494709   \n",
       "25%         0.651741                       0.610227   \n",
       "50%         0.680556                       0.672078   \n",
       "75%         0.702213                       0.706385   \n",
       "max         0.843915                       0.877273   \n",
       "\n",
       "       decision tree{'criterion': 'entropy'}  \\\n",
       "count                              50.000000   \n",
       "mean                                0.616725   \n",
       "std                                 0.066822   \n",
       "min                                 0.430556   \n",
       "25%                                 0.581349   \n",
       "50%                                 0.614340   \n",
       "75%                                 0.660958   \n",
       "max                                 0.763636   \n",
       "\n",
       "       decision tree{'criterion': 'gini'}  elastic net{'max_iter': 10000}  \n",
       "count                           50.000000                            50.0  \n",
       "mean                             0.614753                             0.5  \n",
       "std                              0.056164                             0.0  \n",
       "min                              0.492063                             0.5  \n",
       "25%                              0.577679                             0.5  \n",
       "50%                              0.614286                             0.5  \n",
       "75%                              0.646807                             0.5  \n",
       "max                              0.742063                             0.5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_screen_mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ae31f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7922077922077921\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7506493506493506\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.8121693121693122\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.20899470899470898\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7857142857142857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.812169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.750649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__gamma': '...</td>\n",
       "      <td>0.208995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__C': 1.0, 'classifier__gamma': 'a...  0.812169\n",
       "1  {'classifier__C': 1.0, 'classifier__gamma': 'a...  0.792208\n",
       "2  {'classifier__C': 1.0, 'classifier__gamma': 'a...  0.785714\n",
       "3  {'classifier__C': 1.0, 'classifier__gamma': 'a...  0.750649\n",
       "4  {'classifier__C': 0.01, 'classifier__gamma': '...  0.208995"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune SVM\n",
    "\n",
    "fname_text = 'experiments/dsd/mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/dsd/mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = SVC(probability = True), param_grid = svm_grid, X_train = X_train_mt_dsd, \n",
    "            y_train = y_train_dsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b8014bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.6311688311688312\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.7922077922077921\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__max_depth': 20.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 20.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6507936507936508\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 60.0, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.8029100529100529\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 2000, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 2000, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.8518518518518519\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__max_depth': 100.0, 'classifier__...</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__max_depth': 60.0, 'classifier__m...</td>\n",
       "      <td>0.802910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__max_depth': 80.0, 'classifier__m...</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__max_depth': 20.0, 'classifier__m...</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__max_depth': 80.0, 'classifier__m...</td>\n",
       "      <td>0.631169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__max_depth': 100.0, 'classifier__...  0.851852\n",
       "1  {'classifier__max_depth': 60.0, 'classifier__m...  0.802910\n",
       "2  {'classifier__max_depth': 80.0, 'classifier__m...  0.792208\n",
       "3  {'classifier__max_depth': 20.0, 'classifier__m...  0.650794\n",
       "4  {'classifier__max_depth': 80.0, 'classifier__m...  0.631169"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune RF\n",
    "\n",
    "fname_text = 'experiments/dsd/mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/dsd/mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = RandomForestClassifier(), param_grid = rf_grid, X_train = X_train_mt_dsd, \n",
    "            y_train = y_train_dsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "91979995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__beta_1': 0.3, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (20, 20, 20), 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.3, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (20, 20, 20), 'preprocessor__cat__selector__percentile': 70.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6857142857142857\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__beta_1': 0.9, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (10, 10), 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__beta_1': 0.9, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (10, 10), 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.7753246753246753\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 60.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 60.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7857142857142857\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30), 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30), 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7566137566137566\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.6197089947089947\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__beta_1': 0.6000000000000001, 'cl...</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__beta_1': 0.9, 'classifier__beta_...</td>\n",
       "      <td>0.775325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__beta_1': 0.6000000000000001, 'cl...</td>\n",
       "      <td>0.756614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__beta_1': 0.3, 'classifier__beta_...</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__beta_1': 0.6000000000000001, 'cl...</td>\n",
       "      <td>0.619709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__beta_1': 0.6000000000000001, 'cl...  0.785714\n",
       "1  {'classifier__beta_1': 0.9, 'classifier__beta_...  0.775325\n",
       "2  {'classifier__beta_1': 0.6000000000000001, 'cl...  0.756614\n",
       "3  {'classifier__beta_1': 0.3, 'classifier__beta_...  0.685714\n",
       "4  {'classifier__beta_1': 0.6000000000000001, 'cl...  0.619709"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune MLP\n",
    "\n",
    "fname_text = 'experiments/dsd/mt_data/mlp_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/dsd/mt_data/mlp_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = MLPClassifier(max_iter = 10000), param_grid = mlp_grid, X_train = X_train_mt_dsd, \n",
    "            y_train = y_train_dsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "75b1f02e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for RandomForestClassifier(max_depth=100, min_samples_leaf=4, n_estimators=2000)\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=0)),\n",
       "                                                                  ('variance_threshold',\n",
       "                                                                   VarianceThreshold(threshold=0.4)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'heparin',\n",
       "                                                   'num_pas...\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'ptas',\n",
       "                                                   'stent_ret', 'aspiration',\n",
       "                                                   'first_pass_reperf',\n",
       "                                                   'procedure_ap', 'gen_anes',\n",
       "                                                   'hypoten_mt', 'tici_success',\n",
       "                                                   'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('SMOTE', SMOTE()),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_depth=100, min_samples_leaf=4,\n",
       "                                        n_estimators=2000))])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain best model on entire training set and save model\n",
    "\n",
    "retrain_save(X = X_train_mt_dsd, \n",
    "             y = y_train_dsd, \n",
    "             percentile = 30, \n",
    "             threshold = 0.4, \n",
    "             final_model = RandomForestClassifier(max_depth = 100, min_samples_leaf = 4, min_samples_split = 2, \n",
    "                                                 n_estimators = 2000), \n",
    "             fname = 'models/dsd/mt_data/final_rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cf7c6fcd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=42)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'heparin',\n",
       "                                                   'num_pass', 'fluoro_time',\n",
       "                                                   'time_to_arr',\n",
       "                                                   'time_to_puncture',\n",
       "                                                   'time...\n",
       "                                                   'stroke_etiol', 'sex',\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'ptas',\n",
       "                                                   'stent_ret', 'aspiration',\n",
       "                                                   'first_pass_reperf',\n",
       "                                                   'procedure_ap', 'gen_anes',\n",
       "                                                   'hypoten_mt', 'tici_success',\n",
       "                                                   'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('logistic regression',\n",
       "                 LogisticRegression(max_iter=10000, penalty='none',\n",
       "                                    random_state=42))])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train LR model on entire training set and save model\n",
    "\n",
    "train_save_lr(X = X_train_mt_dsd, \n",
    "             y = y_train_dsd, \n",
    "             fname = 'models/dsd/mt_data/final_lr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621a428",
   "metadata": {},
   "source": [
    "### 6. Death or severe disability prediction - without MT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4cc48f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nomt_dsd = pd.read_pickle('transformed_datasets/dsd/no_mt_data/X_train_trans_nomt.pkl')\n",
    "y_train_dsd = np.load('transformed_datasets/dsd/y_train_trans.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1c00a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline logistic regression model with CV using 5 splits and 10 repeats\n",
      "Mean AUC for baseline logistic regression model: 0.710118807118807 +/- 0.07409231233684198\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline LR model\n",
    "\n",
    "pipe_lr_nomt_dsd, scores_lr_nomt_dsd = baseline_lr(X_train = X_train_nomt_dsd, y_train = y_train_dsd, \n",
    "                                                     n_splits = 5, n_repeats = 10, scoring = 'roc_auc', \n",
    "                                                 fname = 'experiments/dsd/no_mt_data/baseline_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ab316c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating elastic net...\n",
      "Evaluating decision tree...\n",
      "Evaluating random forest...\n",
      "Evaluating k neighbors...\n",
      "Evaluating naive bayes...\n",
      "Evaluating support vector machines...\n",
      "Evaluating XG boost...\n",
      "Evaluating Light GBM...\n",
      "Evaluating MLP...\n"
     ]
    }
   ],
   "source": [
    "# screen models\n",
    "\n",
    "fname = 'experiments/dsd/no_mt_data/init_screening_summary' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_df = 'experiments/dsd/no_mt_data/init_screening_results' + '_' + str(datetime.now().year) + \\\n",
    "    '_' + str(datetime.now().month) + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl' \n",
    "\n",
    "init_screen_nomt = screen_models(models = models, score = 'roc_auc', X_train = X_train_nomt_dsd, \n",
    "                               y_train = y_train_dsd, fname = fname, fname_df = fname_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4741ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support vector machines{'C': 0.1}</th>\n",
       "      <th>random forest{'criterion': 'gini', 'n_estimators': 500}</th>\n",
       "      <th>random forest{'criterion': 'entropy', 'n_estimators': 500}</th>\n",
       "      <th>support vector machines{'C': 0.01}</th>\n",
       "      <th>support vector machines{'C': 1}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}</th>\n",
       "      <th>XG boost{'use_label_encoder': False}</th>\n",
       "      <th>Light GBM{}</th>\n",
       "      <th>naive bayes{}</th>\n",
       "      <th>k neighbors{'n_neighbors': 5}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}</th>\n",
       "      <th>support vector machines{'C': 10}</th>\n",
       "      <th>k neighbors{'n_neighbors': 3}</th>\n",
       "      <th>MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}</th>\n",
       "      <th>decision tree{'criterion': 'entropy'}</th>\n",
       "      <th>decision tree{'criterion': 'gini'}</th>\n",
       "      <th>elastic net{'max_iter': 10000}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.703814</td>\n",
       "      <td>0.689284</td>\n",
       "      <td>0.703496</td>\n",
       "      <td>0.706095</td>\n",
       "      <td>0.695691</td>\n",
       "      <td>0.646703</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.642510</td>\n",
       "      <td>0.649688</td>\n",
       "      <td>0.620783</td>\n",
       "      <td>0.629017</td>\n",
       "      <td>0.612499</td>\n",
       "      <td>0.621181</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.566118</td>\n",
       "      <td>0.567456</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.069848</td>\n",
       "      <td>0.051269</td>\n",
       "      <td>0.058830</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>0.057399</td>\n",
       "      <td>0.061220</td>\n",
       "      <td>0.067535</td>\n",
       "      <td>0.055169</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>0.076589</td>\n",
       "      <td>0.064498</td>\n",
       "      <td>0.063417</td>\n",
       "      <td>0.058193</td>\n",
       "      <td>0.067454</td>\n",
       "      <td>0.066270</td>\n",
       "      <td>0.056477</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.514550</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.583995</td>\n",
       "      <td>0.588624</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.470899</td>\n",
       "      <td>0.484127</td>\n",
       "      <td>0.476623</td>\n",
       "      <td>0.375325</td>\n",
       "      <td>0.482804</td>\n",
       "      <td>0.443122</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.480159</td>\n",
       "      <td>0.393506</td>\n",
       "      <td>0.450649</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.653274</td>\n",
       "      <td>0.651455</td>\n",
       "      <td>0.661454</td>\n",
       "      <td>0.656006</td>\n",
       "      <td>0.604004</td>\n",
       "      <td>0.596771</td>\n",
       "      <td>0.607804</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.584656</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.580026</td>\n",
       "      <td>0.577050</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.524675</td>\n",
       "      <td>0.533730</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.706373</td>\n",
       "      <td>0.700397</td>\n",
       "      <td>0.699916</td>\n",
       "      <td>0.696104</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.655844</td>\n",
       "      <td>0.651455</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.650673</td>\n",
       "      <td>0.630291</td>\n",
       "      <td>0.623846</td>\n",
       "      <td>0.621032</td>\n",
       "      <td>0.617641</td>\n",
       "      <td>0.616655</td>\n",
       "      <td>0.567172</td>\n",
       "      <td>0.565873</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.759055</td>\n",
       "      <td>0.724351</td>\n",
       "      <td>0.748181</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.688173</td>\n",
       "      <td>0.684854</td>\n",
       "      <td>0.684193</td>\n",
       "      <td>0.714084</td>\n",
       "      <td>0.677579</td>\n",
       "      <td>0.667659</td>\n",
       "      <td>0.656818</td>\n",
       "      <td>0.652477</td>\n",
       "      <td>0.674026</td>\n",
       "      <td>0.603671</td>\n",
       "      <td>0.605159</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.820106</td>\n",
       "      <td>0.789610</td>\n",
       "      <td>0.822727</td>\n",
       "      <td>0.851948</td>\n",
       "      <td>0.816138</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.784392</td>\n",
       "      <td>0.738961</td>\n",
       "      <td>0.787013</td>\n",
       "      <td>0.770130</td>\n",
       "      <td>0.759740</td>\n",
       "      <td>0.755291</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.762338</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.684524</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       support vector machines{'C': 0.1}  \\\n",
       "count                          50.000000   \n",
       "mean                            0.703814   \n",
       "std                             0.069848   \n",
       "min                             0.514550   \n",
       "25%                             0.660053   \n",
       "50%                             0.706373   \n",
       "75%                             0.759055   \n",
       "max                             0.820106   \n",
       "\n",
       "       random forest{'criterion': 'gini', 'n_estimators': 500}  \\\n",
       "count                                          50.000000         \n",
       "mean                                            0.689284         \n",
       "std                                             0.051269         \n",
       "min                                             0.523810         \n",
       "25%                                             0.653274         \n",
       "50%                                             0.700397         \n",
       "75%                                             0.724351         \n",
       "max                                             0.789610         \n",
       "\n",
       "       random forest{'criterion': 'entropy', 'n_estimators': 500}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.703496            \n",
       "std                                             0.058830            \n",
       "min                                             0.583995            \n",
       "25%                                             0.651455            \n",
       "50%                                             0.699916            \n",
       "75%                                             0.748181            \n",
       "max                                             0.822727            \n",
       "\n",
       "       support vector machines{'C': 0.01}  support vector machines{'C': 1}  \\\n",
       "count                           50.000000                        50.000000   \n",
       "mean                             0.706095                         0.695691   \n",
       "std                              0.064084                         0.057399   \n",
       "min                              0.588624                         0.545455   \n",
       "25%                              0.661454                         0.656006   \n",
       "50%                              0.696104                         0.692857   \n",
       "75%                              0.750000                         0.736111   \n",
       "max                              0.851948                         0.816138   \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10,), 'max_iter': 10000}  \\\n",
       "count                                          50.000000     \n",
       "mean                                            0.646703     \n",
       "std                                             0.061220     \n",
       "min                                             0.480519     \n",
       "25%                                             0.604004     \n",
       "50%                                             0.655844     \n",
       "75%                                             0.688173     \n",
       "max                                             0.777778     \n",
       "\n",
       "       XG boost{'use_label_encoder': False}  Light GBM{}  naive bayes{}  \\\n",
       "count                             50.000000    50.000000      50.000000   \n",
       "mean                               0.642336     0.642510       0.649688   \n",
       "std                                0.067535     0.055169       0.077715   \n",
       "min                                0.470899     0.484127       0.476623   \n",
       "25%                                0.596771     0.607804       0.613757   \n",
       "50%                                0.651455     0.650794       0.650673   \n",
       "75%                                0.684854     0.684193       0.714084   \n",
       "max                                0.784392     0.738961       0.787013   \n",
       "\n",
       "       k neighbors{'n_neighbors': 5}  \\\n",
       "count                      50.000000   \n",
       "mean                        0.620783   \n",
       "std                         0.076589   \n",
       "min                         0.375325   \n",
       "25%                         0.584656   \n",
       "50%                         0.630291   \n",
       "75%                         0.677579   \n",
       "max                         0.770130   \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10, 10), 'max_iter': 10000}  \\\n",
       "count                                          50.000000            \n",
       "mean                                            0.629017            \n",
       "std                                             0.064498            \n",
       "min                                             0.482804            \n",
       "25%                                             0.595238            \n",
       "50%                                             0.623846            \n",
       "75%                                             0.667659            \n",
       "max                                             0.759740            \n",
       "\n",
       "       support vector machines{'C': 10}  k neighbors{'n_neighbors': 3}  \\\n",
       "count                         50.000000                      50.000000   \n",
       "mean                           0.612499                       0.621181   \n",
       "std                            0.063417                       0.058193   \n",
       "min                            0.443122                       0.511905   \n",
       "25%                            0.580026                       0.577050   \n",
       "50%                            0.621032                       0.617641   \n",
       "75%                            0.656818                       0.652477   \n",
       "max                            0.755291                       0.746032   \n",
       "\n",
       "       MLP{'hidden_layer_sizes': (10, 10), 'max_iter': 10000}  \\\n",
       "count                                          50.000000        \n",
       "mean                                            0.618557        \n",
       "std                                             0.067454        \n",
       "min                                             0.480159        \n",
       "25%                                             0.571429        \n",
       "50%                                             0.616655        \n",
       "75%                                             0.674026        \n",
       "max                                             0.762338        \n",
       "\n",
       "       decision tree{'criterion': 'entropy'}  \\\n",
       "count                              50.000000   \n",
       "mean                                0.566118   \n",
       "std                                 0.066270   \n",
       "min                                 0.393506   \n",
       "25%                                 0.524675   \n",
       "50%                                 0.567172   \n",
       "75%                                 0.603671   \n",
       "max                                 0.708333   \n",
       "\n",
       "       decision tree{'criterion': 'gini'}  elastic net{'max_iter': 10000}  \n",
       "count                           50.000000                            50.0  \n",
       "mean                             0.567456                             0.5  \n",
       "std                              0.056477                             0.0  \n",
       "min                              0.450649                             0.5  \n",
       "25%                              0.533730                             0.5  \n",
       "50%                              0.565873                             0.5  \n",
       "75%                              0.605159                             0.5  \n",
       "max                              0.684524                             0.5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_screen_nomt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4feaccf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.6753246753246753\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 0.01, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.3181818181818182\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__C': 0.1, 'classifier__gamma': 'scale', 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__C': 0.1, 'classifier__gamma': 'scale', 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.6858465608465609\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__C': 1.0, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7103174603174603\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.8465608465608465\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.846561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.710317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__gamma': 's...</td>\n",
       "      <td>0.685847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__gamma': 'a...</td>\n",
       "      <td>0.675325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__gamma': '...</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__C': 0.1, 'classifier__gamma': 'a...  0.846561\n",
       "1  {'classifier__C': 1.0, 'classifier__gamma': 'a...  0.710317\n",
       "2  {'classifier__C': 0.1, 'classifier__gamma': 's...  0.685847\n",
       "3  {'classifier__C': 0.1, 'classifier__gamma': 'a...  0.675325\n",
       "4  {'classifier__C': 0.01, 'classifier__gamma': '...  0.318182"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune SVM\n",
    "\n",
    "fname_text = 'experiments/dsd/no_mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/dsd/no_mt_data/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = SVC(probability = True), param_grid = svm_grid, X_train = X_train_nomt_dsd, \n",
    "            y_train = y_train_dsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cc9edb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__max_depth': 40.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__max_depth': 40.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 500, 'preprocessor__cat__selector__percentile': 40.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.7818181818181817\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 1500, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 1500, 'preprocessor__cat__selector__percentile': 20.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.7857142857142857\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__max_depth': 20.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1500, 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__max_depth': 20.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1500, 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.828042328042328\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__max_depth': 100.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 1000, 'preprocessor__cat__selector__percentile': 30.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.5740740740740741\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 1500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "parameters: {'classifier__max_depth': 80.0, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 1500, 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.6}\n",
      "AUC score: 0.6296296296296297\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__max_depth': 20.0, 'classifier__m...</td>\n",
       "      <td>0.828042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__max_depth': 80.0, 'classifier__m...</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__max_depth': 40.0, 'classifier__m...</td>\n",
       "      <td>0.781818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__max_depth': 80.0, 'classifier__m...</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__max_depth': 100.0, 'classifier__...</td>\n",
       "      <td>0.574074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__max_depth': 20.0, 'classifier__m...  0.828042\n",
       "1  {'classifier__max_depth': 80.0, 'classifier__m...  0.785714\n",
       "2  {'classifier__max_depth': 40.0, 'classifier__m...  0.781818\n",
       "3  {'classifier__max_depth': 80.0, 'classifier__m...  0.629630\n",
       "4  {'classifier__max_depth': 100.0, 'classifier__...  0.574074"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune RF\n",
    "\n",
    "fname_text = 'experiments/dsd/no_mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/dsd/no_mt_data/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = RandomForestClassifier(), param_grid = rf_grid, X_train = X_train_nomt_dsd, \n",
    "            y_train = y_train_dsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "183ea47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 1\n",
      "{'classifier__beta_1': 0.9, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (20,), 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.9, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (20,), 'preprocessor__cat__selector__percentile': 50.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6597402597402597\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 2\n",
      "{'classifier__beta_1': 0.3, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (10, 10, 10), 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__beta_1': 0.3, 'classifier__beta_2': 0.9, 'classifier__hidden_layer_sizes': (10, 10, 10), 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.6727272727272727\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 3\n",
      "{'classifier__beta_1': 0.3, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (30, 30), 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.3, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (30, 30), 'preprocessor__cat__selector__percentile': 10.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6362433862433863\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 4\n",
      "{'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "parameters: {'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.6000000000000001, 'classifier__hidden_layer_sizes': (30, 30, 30), 'preprocessor__cat__selector__percentile': 100.0, 'preprocessor__cont__variance_threshold__threshold': 0.4}\n",
      "AUC score: 0.6574074074074074\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n",
      "evaluating model for fold number 5\n",
      "{'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (10,), 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "parameters: {'classifier__beta_1': 0.6000000000000001, 'classifier__beta_2': 0.3, 'classifier__hidden_layer_sizes': (10,), 'preprocessor__cat__selector__percentile': 80.0, 'preprocessor__cont__variance_threshold__threshold': 0.5}\n",
      "AUC score: 0.5714285714285714\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'classifier__beta_1': 0.3, 'classifier__beta_...</td>\n",
       "      <td>0.672727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'classifier__beta_1': 0.9, 'classifier__beta_...</td>\n",
       "      <td>0.659740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'classifier__beta_1': 0.6000000000000001, 'cl...</td>\n",
       "      <td>0.657407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'classifier__beta_1': 0.3, 'classifier__beta_...</td>\n",
       "      <td>0.636243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'classifier__beta_1': 0.6000000000000001, 'cl...</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     score\n",
       "0  {'classifier__beta_1': 0.3, 'classifier__beta_...  0.672727\n",
       "1  {'classifier__beta_1': 0.9, 'classifier__beta_...  0.659740\n",
       "2  {'classifier__beta_1': 0.6000000000000001, 'cl...  0.657407\n",
       "3  {'classifier__beta_1': 0.3, 'classifier__beta_...  0.636243\n",
       "4  {'classifier__beta_1': 0.6000000000000001, 'cl...  0.571429"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune MLP\n",
    "\n",
    "fname_text = 'experiments/dsd/no_mt_data/mlp_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "fname_results = 'experiments/dsd/no_mt_data/mlp_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.pkl'\n",
    "\n",
    "eval_params(fname_text = fname_text, fname_results = fname_results, \n",
    "            tuning_model = MLPClassifier(max_iter = 10000), param_grid = mlp_grid, X_train = X_train_nomt_dsd, \n",
    "            y_train = y_train_dsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "36bd6818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for RandomForestClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=5,\n",
      "                       n_estimators=1500)\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=0)),\n",
       "                                                                  ('variance_threshold',\n",
       "                                                                   VarianceThreshold(threshold=0.4)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'time_to_arr']),\n",
       "                                                 ('...\n",
       "                                                                                    score_func=<function chi2 at 0x7fb3db3df670>))]),\n",
       "                                                  ['hypox', 'wake_up',\n",
       "                                                   'seizure', 'transfer', 'tpa',\n",
       "                                                   'stroke_etiol', 'sex',\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('SMOTE', SMOTE()),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_depth=20, min_samples_leaf=4,\n",
       "                                        min_samples_split=5,\n",
       "                                        n_estimators=1500))])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain best model on entire training set and save model\n",
    "\n",
    "retrain_save(X = X_train_nomt_dsd, \n",
    "             y = y_train_dsd, \n",
    "             percentile = 80, \n",
    "             threshold = 0.4, \n",
    "             final_model = RandomForestClassifier(max_depth = 20, min_samples_leaf = 4, min_samples_split = 5, \n",
    "                                                 n_estimators = 1500), \n",
    "             fname = 'models/dsd/no_mt_data/final_rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d49fc900",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cont',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(max_iter=10000,\n",
       "                                                                                    random_state=42)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['glucose', 'calcium', 'mag',\n",
       "                                                   'phos', 'inr', 'plt',\n",
       "                                                   'plt_lymph', 'sbp',\n",
       "                                                   'nih_admit', 'age', 'bmi',\n",
       "                                                   'aspects', 'time_to_arr']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('ordinal '\n",
       "                                                                   'encoder',\n",
       "                                                                   OrdinalEncoder...\n",
       "                                                                  ('one hot '\n",
       "                                                                   'encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['hypox', 'wake_up',\n",
       "                                                   'seizure', 'transfer', 'tpa',\n",
       "                                                   'stroke_etiol', 'sex',\n",
       "                                                   'race', 'htn', 'dm', 'ckd',\n",
       "                                                   'hld', 'afib', 'smoking',\n",
       "                                                   'prior_stroke', 'ac_ap',\n",
       "                                                   'left', 'occ_site', 'tandem',\n",
       "                                                   'hyperdense', 'coll_full',\n",
       "                                                   'pre_mrs_0'])])),\n",
       "                ('logistic regression',\n",
       "                 LogisticRegression(max_iter=10000, penalty='none',\n",
       "                                    random_state=42))])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train LR model on entire training set and save model\n",
    "\n",
    "train_save_lr(X = X_train_nomt_dsd, \n",
    "             y = y_train_dsd, \n",
    "             fname = 'models/dsd/no_mt_data/final_lr_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
